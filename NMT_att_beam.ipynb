{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NMT_att_beam.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "KANy4a24hGtY"
      },
      "source": [
        "try:\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtZRAGJChcvj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "61f287ce-48bc-43f0-dc7e-659b1db8a87b"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "print(tf.__version__)\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "import io\n",
        "import numpy as np\n",
        "import re\n",
        "import unicodedata\n",
        "import urllib3\n",
        "import shutil\n",
        "import zipfile\n",
        "import itertools\n",
        "from google.colab import drive"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0-rc2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tF6e0hWwi-yJ"
      },
      "source": [
        "Download File"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdwjW9MbiiJY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "95f989cf-622e-4dc3-efb4-f999cd40464a"
      },
      "source": [
        "http = urllib3.PoolManager()\n",
        "url ='http://www.manythings.org/anki/fra-eng.zip'\n",
        "filename = 'fra-eng.zip'\n",
        "path = os.getcwd()\n",
        "zipfilename = os.path.join(path, filename)\n",
        "with http.request('GET', url, preload_content=False) as r, open(zipfilename, 'wb') as out_file:       \n",
        "    shutil.copyfileobj(r, out_file)\n",
        "print(zipfilename)\n",
        "with zipfile.ZipFile(zipfilename, 'r') as zip_ref:\n",
        "    zip_ref.extractall(path)\n",
        "!ls /content/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/fra-eng.zip\n",
            "_about.txt  fra-eng.zip  fra.txt  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqw14x3aixSO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b7c437ad-efe5-4511-a66b-31df686060d1"
      },
      "source": [
        "!cat /content/fra.txt | wc -l"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "175623\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkGB4MlUi8FY"
      },
      "source": [
        "Preprocess File"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-wd83uui9rW"
      },
      "source": [
        "def read_file(filename):\n",
        "    path = os.getcwd()\n",
        "    path = os.path.join(path, filename)\n",
        "    file = io.open(path,encoding='UTF-8')\n",
        "    lines = file.read()\n",
        "    file.close()\n",
        "    return lines"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMk93zYMjDc3"
      },
      "source": [
        "def unicode_to_ascii(s):\n",
        "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrJIGehzjFtA"
      },
      "source": [
        "# For non-english characterset translations such as Hindi, Russian, etc. we keep unicode. \n",
        "def preprocess_sentence(s):\n",
        "    s = unicode_to_ascii(s.lower().strip())\n",
        "    s = s.lower().strip()\n",
        "    # creating a space between a word and the punctuation following it\n",
        "    # eg: \"he is a boy.\" => \"he is a boy .\"\n",
        "    # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
        "    s = re.sub(r\"([?.!,¿])\", r\" \\1 \", s)\n",
        "    s = re.sub(r'[\" \"]+', \" \", s)\n",
        "    # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
        "    s = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", s)\n",
        "\n",
        "    s = s.rstrip().strip()\n",
        "    # adding a start and an end token to the sentence\n",
        "    # so that the model know when to start and stop predicting.\n",
        "    s = '<start> ' + s + ' <end>'\n",
        "    return s"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-ucdaYojLBA"
      },
      "source": [
        "Create Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTHsrCbZjJnM"
      },
      "source": [
        "def create_dataset(filename, num_samples):\n",
        "    path = os.getcwd()\n",
        "    path = os.path.join(path, filename)\n",
        "    file = io.open(path,encoding='UTF-8')\n",
        "    lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
        "\n",
        "    word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')]  for l in lines[:num_samples]]\n",
        "\n",
        "    return zip(*word_pairs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvMp36vXjPrQ"
      },
      "source": [
        "X_text,Y_text,_  = create_dataset(\"fra.txt\", num_samples=5000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TV53HhlrjSex",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3ccb1f98-213f-4cac-cca4-1e4858ae6072"
      },
      "source": [
        "print(X_text[4000:4001])\n",
        "print(Y_text[4000:4001])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('<start> i m too busy . <end>',)\n",
            "('<start> je suis trop occupe . <end>',)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fC8na5-5jWBA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b2d39503-8483-4d5f-b726-5567bb8d2637"
      },
      "source": [
        "#total samples\n",
        "print(\"Total Samples : \", len(X_text))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Samples :  5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RVlKZdAjaaa"
      },
      "source": [
        "# create a function to tokenize words into index using inbuild tokenizer vocabulory\n",
        "# important to override filter otherwise it will filter out all punctuation,\n",
        "# plus tabs and line breaks, minus the ' character.\n",
        "def tokenize(input):\n",
        "   tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
        "   tokenizer.fit_on_texts(input)\n",
        "   sequences = tokenizer.texts_to_sequences(input)\n",
        "  # print(max_len(sequences))\n",
        "   sequences = tf.keras.preprocessing.sequence.pad_sequences(sequences, padding='post')\n",
        "   return  sequences, tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_-wNg3mjdMa"
      },
      "source": [
        "def max_len(tensor):\n",
        "    #print( np.argmax([len(t) for t in tensor]))\n",
        "    return max( len(t) for t in tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwtV8yCljjlf"
      },
      "source": [
        "# Tokenize each word into index and return the tokenized list and tokenizer\n",
        "X , X_tokenizer = tokenize(X_text)\n",
        "Y, Y_tokenizer = tokenize(Y_text)\n",
        "X_train,  X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.2)\n",
        "\n",
        "Tx = max_len(X)\n",
        "Ty = max_len(Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rk_KVxfjmm9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "2fa09adc-0b38-4ab0-8341-f3308427a293"
      },
      "source": [
        "print(\"Max length English sentence denoted as Tx : \", Tx)\n",
        "print(\"Max length French sentence denoted as Ty: \", Ty)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max length English sentence denoted as Tx :  8\n",
            "Max length French sentence denoted as Ty:  15\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIcJwBhwkABB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1d6a8ffb-3ca6-4bfa-fa2f-ff8c1929a4ea"
      },
      "source": [
        "X_tokenizer.word_index['<start>'] #'<start>': 2   # tokenize by frequency\n",
        "input_vocab_size = len(X_tokenizer.word_index)+1  # add 1 for 0 sequence character\n",
        "output_vocab_size = len(Y_tokenizer.word_index)+ 1\n",
        "print(\"input_vocab_size : \", input_vocab_size)\n",
        "print(\"output_vocab_size : \" ,output_vocab_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input_vocab_size :  1218\n",
            "output_vocab_size :  2368\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vf6lCnOKkXMK"
      },
      "source": [
        "Model Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glytAsRXkaCm"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = len(X_train)\n",
        "steps_per_epoch = BUFFER_SIZE//BATCH_SIZE\n",
        "embedding_dims = 256\n",
        "rnn_units = 1024\n",
        "dense_units = 1024\n",
        "Dtype = tf.float32   #used to initialize DecoderCell Zero state"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twO3pa4kkcxx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "2e23c44b-5c11-401b-ed62-cff894d0a5dd"
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices((X_train, Y_train)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
        "example_X, example_Y = next(iter(dataset))\n",
        "print(example_X.shape) \n",
        "print(example_Y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 8)\n",
            "(64, 15)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1N9mdUikqST",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ebc3424f-b92a-49e0-8cae-853c8f8ef2c2"
      },
      "source": [
        "dataset_test = tf.data.Dataset.from_tensor_slices((X_test, Y_test)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
        "example_X, example_Y = next(iter(dataset))\n",
        "print(example_X.shape) \n",
        "print(example_Y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 8)\n",
            "(64, 15)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4efblZnk3ag"
      },
      "source": [
        "Creating Encoder-Decoder Model based on tfa.seq2seq module"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6_3ki9hk7Y5"
      },
      "source": [
        "Define Model\n",
        "The encoder network consists of an encoder embedding layer and a LSTM layer.\n",
        "\n",
        "The decoder network encompasses both decoder and attention mechanism.\n",
        "\n",
        "The example uses LuongAttention."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZghzfyek_CB"
      },
      "source": [
        "#ENCODER\n",
        "class EncoderNetwork(tf.keras.Model):\n",
        "    def __init__(self,input_vocab_size,embedding_dims, rnn_units ):\n",
        "        super().__init__()\n",
        "        self.encoder_embedding = tf.keras.layers.Embedding(input_dim=input_vocab_size,\n",
        "                                                           output_dim=embedding_dims)\n",
        "        self.encoder_rnnlayer = tf.keras.layers.LSTM(rnn_units,return_sequences=True, \n",
        "                                                     return_state=True )\n",
        "    \n",
        "#DECODER\n",
        "class DecoderNetwork(tf.keras.Model):\n",
        "    def __init__(self,output_vocab_size, embedding_dims, rnn_units):\n",
        "        super().__init__()\n",
        "        self.decoder_embedding = tf.keras.layers.Embedding(input_dim=output_vocab_size,\n",
        "                                                           output_dim=embedding_dims) \n",
        "        self.dense_layer = tf.keras.layers.Dense(output_vocab_size)\n",
        "        self.decoder_rnncell = tf.keras.layers.LSTMCell(rnn_units)\n",
        "        # Sampler\n",
        "        self.sampler = tfa.seq2seq.sampler.TrainingSampler()\n",
        "        # Create attention mechanism with memory = None\n",
        "        self.attention_mechanism = self.build_attention_mechanism(dense_units,None,BATCH_SIZE*[Tx])\n",
        "        self.rnn_cell =  self.build_rnn_cell(BATCH_SIZE)\n",
        "        self.decoder = tfa.seq2seq.BasicDecoder(self.rnn_cell, sampler= self.sampler,\n",
        "                                                output_layer=self.dense_layer)\n",
        "\n",
        "    def build_attention_mechanism(self, units,memory, memory_sequence_length):\n",
        "        return tfa.seq2seq.LuongAttention(units, memory = memory, \n",
        "                                          memory_sequence_length=memory_sequence_length)\n",
        "        #return tfa.seq2seq.BahdanauAttention(units, memory = memory, memory_sequence_length=memory_sequence_length)\n",
        "\n",
        "    # wrap decodernn cell  \n",
        "    def build_rnn_cell(self, batch_size ):\n",
        "        rnn_cell = tfa.seq2seq.AttentionWrapper(self.decoder_rnncell, self.attention_mechanism,\n",
        "                                                attention_layer_size=dense_units)\n",
        "        return rnn_cell\n",
        "    \n",
        "    def build_decoder_initial_state(self, batch_size, encoder_state,Dtype):\n",
        "        decoder_initial_state = self.rnn_cell.get_initial_state(batch_size = batch_size, \n",
        "                                                                dtype = Dtype)\n",
        "        decoder_initial_state = decoder_initial_state.clone(cell_state=encoder_state) \n",
        "        return decoder_initial_state\n",
        "\n",
        "\n",
        "\n",
        "encoderNetwork = EncoderNetwork(input_vocab_size,embedding_dims, rnn_units)\n",
        "decoderNetwork = DecoderNetwork(output_vocab_size,embedding_dims, rnn_units)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14l16AzQlIr6"
      },
      "source": [
        "Optimizer and Custom Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0v_Ptx3lKhK"
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTExNNIFlOPW"
      },
      "source": [
        "Here, mask is a zero-one matrix of the same size as decoder_outputs. It masks padding positions outside of the target sequence lengths with values 0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woY6POfElR5y"
      },
      "source": [
        "def loss_function(y_pred, y):\n",
        "   \n",
        "    #shape of y [batch_size, ty]\n",
        "    #shape of y_pred [batch_size, Ty, output_vocab_size] \n",
        "    sparsecategoricalcrossentropy = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True,\n",
        "                                                                                  reduction='none')\n",
        "    loss = sparsecategoricalcrossentropy(y_true=y, y_pred=y_pred)\n",
        "    #skip loss calculation for padding sequences i.e. y = 0 \n",
        "    #[ <start>,How, are, you, today, 0, 0, 0, 0 ....<end>]\n",
        "    #[ 1, 234, 3, 423, 3344, 0, 0 ,0 ,0, 2 ]\n",
        "    # y is a tensor of [batch_size,Ty] . Create a mask when [y=0]\n",
        "    # mask the loss when padding sequence appears in the output sequence\n",
        "    mask = tf.logical_not(tf.math.equal(y,0))   #output 0 for y=0 else output 1\n",
        "    mask = tf.cast(mask, dtype=loss.dtype)\n",
        "    loss = mask* loss\n",
        "    loss = tf.reduce_mean(loss)\n",
        "    return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDLxTR74lcNS"
      },
      "source": [
        "To begin with, attention mechanism is initialized without memory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-A7fC6-alaMD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e7036192-5f27-4f28-e24a-e61fefdba63d"
      },
      "source": [
        "decoderNetwork.attention_mechanism.memory_initialized"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nopN_nHAlf3D"
      },
      "source": [
        "One step of training on a batch using Teacher Forcing technique"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSBLSEBEljRs"
      },
      "source": [
        "def train_step(input_batch, output_batch,encoder_initial_cell_state):\n",
        "    #initialize loss = 0\n",
        "    loss = 0\n",
        "    with tf.GradientTape() as tape:\n",
        "        encoder_emb_inp = encoderNetwork.encoder_embedding(input_batch)\n",
        "        a, a_tx, c_tx = encoderNetwork.encoder_rnnlayer(encoder_emb_inp, \n",
        "                                                        initial_state =encoder_initial_cell_state)\n",
        "\n",
        "        #[last step activations,last memory_state] of encoder passed as input to decoder Network\n",
        "        \n",
        "         \n",
        "        # Prepare correct Decoder input & output sequence data\n",
        "        decoder_input = output_batch[:,:-1] # ignore <end>\n",
        "        #compare logits with timestepped +1 version of decoder_input\n",
        "        decoder_output = output_batch[:,1:] #ignore <start>\n",
        "\n",
        "\n",
        "        # Decoder Embeddings\n",
        "        decoder_emb_inp = decoderNetwork.decoder_embedding(decoder_input)\n",
        "\n",
        "        #Setting up decoder memory from encoder output and Zero State for AttentionWrapperState\n",
        "        decoderNetwork.attention_mechanism.setup_memory(a)\n",
        "        decoder_initial_state = decoderNetwork.build_decoder_initial_state(BATCH_SIZE,\n",
        "                                                                           encoder_state=[a_tx, c_tx],\n",
        "                                                                           Dtype=tf.float32)\n",
        "        \n",
        "        #BasicDecoderOutput        \n",
        "        outputs, _, _ = decoderNetwork.decoder(decoder_emb_inp,initial_state=decoder_initial_state,\n",
        "                                               sequence_length=BATCH_SIZE*[Ty-1])\n",
        "\n",
        "        logits = outputs.rnn_output\n",
        "        #Calculate loss\n",
        "\n",
        "        loss = loss_function(logits, decoder_output)\n",
        "\n",
        "    #Returns the list of all layer variables / weights.\n",
        "    variables = encoderNetwork.trainable_variables + decoderNetwork.trainable_variables  \n",
        "    # differentiate loss wrt variables\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "\n",
        "    #grads_and_vars – List of(gradient, variable) pairs.\n",
        "    grads_and_vars = zip(gradients,variables)\n",
        "    optimizer.apply_gradients(grads_and_vars)\n",
        "    return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j841tItKlrQO"
      },
      "source": [
        "Training\n",
        "get existing checkpoint objects\n",
        "\n",
        "Object based Checkpointing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2FXtYynlneT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "ac44470f-f37d-4f12-ba35-b4742bed2e60"
      },
      "source": [
        "# mount gdrive containing trained checkpoint objects\n",
        "drive.mount('/content/drive', force_remount=True )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36p7-_Bol9zl"
      },
      "source": [
        "\n",
        "We load from previously saved checkpoints from Google Drive if already trained."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYauIxAPp6pM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        },
        "outputId": "c54f9bf0-923b-4938-bca6-22c0a14514b2"
      },
      "source": [
        "!ls \"/content/drive/My Drive/\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " app\n",
            " cats_and_dogs_small_2.h5\n",
            "'Colab Notebooks'\n",
            " DL4CV_ImageNetBundle_k2opt.pdf\n",
            " DL4CV_PractitionerBundle_k2opt.pdf\n",
            " Homework3.1.gdoc\n",
            " NLP\n",
            "'PhD Life'\n",
            " publication_2_21348_203.pdf\n",
            "'[Richard_Bronson,_Govindasami_Naadimuthu]_Schaum'\\''s(BookFi).pdf'\n",
            "'Share Reyna'\n",
            " Untitled4.ipynb\n",
            "'Untitled document (1).gdoc'\n",
            "'Untitled document (2).gdoc'\n",
            "'Untitled document.gdoc'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eB9fU7uhl5Y_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "33bb780f-4e08-4c01-c46e-6a614cc97fea"
      },
      "source": [
        "checkpointdir = os.path.join('/content/drive/My Drive/app',\"nmt_tfa_logs_eng_to_fra_withAttention\")\n",
        "chkpoint_prefix = os.path.join(checkpointdir, \"chkpoint\")\n",
        "if not os.path.exists(checkpointdir):\n",
        "    os.mkdir(checkpointdir)\n",
        "\n",
        "checkpoint = tf.train.Checkpoint(optimizer = optimizer, encoderNetwork = encoderNetwork, \n",
        "                                 decoderNetwork = decoderNetwork)\n",
        "\n",
        "try:\n",
        "    status = checkpoint.restore(tf.train.latest_checkpoint(checkpointdir))\n",
        "    print(\"Checkpoint found at {}\".format(tf.train.latest_checkpoint(checkpointdir)))\n",
        "except:\n",
        "    print(\"No checkpoint found at {}\".format(checkpointdir))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Checkpoint found at None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-yelqX1pb9W"
      },
      "source": [
        "#RNN LSTM hidden and memory state initializer\n",
        "def initialize_initial_state():\n",
        "        return [tf.zeros((BATCH_SIZE, rnn_units)), tf.zeros((BATCH_SIZE, rnn_units))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvDSvlL9pce9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 788
        },
        "outputId": "29debe86-6c51-4252-a5fe-803244fb2e31"
      },
      "source": [
        "epochs = 15\n",
        "for i in range(1, epochs+1):\n",
        "\n",
        "    encoder_initial_cell_state = initialize_initial_state()\n",
        "    total_loss = 0.0\n",
        "\n",
        "\n",
        "    for ( batch , (input_batch, output_batch)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "        batch_loss = train_step(input_batch, output_batch, encoder_initial_cell_state)\n",
        "        total_loss += batch_loss\n",
        "        if (batch+1)%20 == 0:\n",
        "            print(\"total loss: {} epoch {} batch {} \".format(batch_loss.numpy(), i, batch+1))\n",
        "            checkpoint.save(file_prefix = chkpoint_prefix)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total loss: 1.9047019481658936 epoch 1 batch 20 \n",
            "total loss: 1.64083731174469 epoch 1 batch 40 \n",
            "total loss: 1.398915410041809 epoch 1 batch 60 \n",
            "total loss: 1.319084882736206 epoch 2 batch 20 \n",
            "total loss: 1.3285285234451294 epoch 2 batch 40 \n",
            "total loss: 1.2238547801971436 epoch 2 batch 60 \n",
            "total loss: 1.2069791555404663 epoch 3 batch 20 \n",
            "total loss: 1.2110167741775513 epoch 3 batch 40 \n",
            "total loss: 1.1145994663238525 epoch 3 batch 60 \n",
            "total loss: 0.9303284883499146 epoch 4 batch 20 \n",
            "total loss: 0.9673671722412109 epoch 4 batch 40 \n",
            "total loss: 0.9549127817153931 epoch 4 batch 60 \n",
            "total loss: 0.8226152062416077 epoch 5 batch 20 \n",
            "total loss: 0.8680375814437866 epoch 5 batch 40 \n",
            "total loss: 0.8550758361816406 epoch 5 batch 60 \n",
            "total loss: 0.7277464866638184 epoch 6 batch 20 \n",
            "total loss: 0.833488404750824 epoch 6 batch 40 \n",
            "total loss: 0.738253116607666 epoch 6 batch 60 \n",
            "total loss: 0.6421130299568176 epoch 7 batch 20 \n",
            "total loss: 0.7246490716934204 epoch 7 batch 40 \n",
            "total loss: 0.76600182056427 epoch 7 batch 60 \n",
            "total loss: 0.6185854077339172 epoch 8 batch 20 \n",
            "total loss: 0.6363543272018433 epoch 8 batch 40 \n",
            "total loss: 0.6872230172157288 epoch 8 batch 60 \n",
            "total loss: 0.5728617310523987 epoch 9 batch 20 \n",
            "total loss: 0.4965171217918396 epoch 9 batch 40 \n",
            "total loss: 0.5344575643539429 epoch 9 batch 60 \n",
            "total loss: 0.4673619866371155 epoch 10 batch 20 \n",
            "total loss: 0.4722829759120941 epoch 10 batch 40 \n",
            "total loss: 0.4937538802623749 epoch 10 batch 60 \n",
            "total loss: 0.35732099413871765 epoch 11 batch 20 \n",
            "total loss: 0.44227883219718933 epoch 11 batch 40 \n",
            "total loss: 0.43609973788261414 epoch 11 batch 60 \n",
            "total loss: 0.3422228991985321 epoch 12 batch 20 \n",
            "total loss: 0.3634648621082306 epoch 12 batch 40 \n",
            "total loss: 0.40754106640815735 epoch 12 batch 60 \n",
            "total loss: 0.25543567538261414 epoch 13 batch 20 \n",
            "total loss: 0.3217101991176605 epoch 13 batch 40 \n",
            "total loss: 0.36176612973213196 epoch 13 batch 60 \n",
            "total loss: 0.2754524052143097 epoch 14 batch 20 \n",
            "total loss: 0.32805395126342773 epoch 14 batch 40 \n",
            "total loss: 0.37362200021743774 epoch 14 batch 60 \n",
            "total loss: 0.2830744981765747 epoch 15 batch 20 \n",
            "total loss: 0.2339238077402115 epoch 15 batch 40 \n",
            "total loss: 0.26023223996162415 epoch 15 batch 60 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sz6CIiStrAEq"
      },
      "source": [
        "Inference\n",
        "Create input sequence to pass to encoder.\n",
        "\n",
        "The input to the decoder at each time step is its previous predictions along with the hidden state and the encoder output.\n",
        "\n",
        "Stop predicting when the model predicts the end token.\n",
        "\n",
        "And store the attention weights for every time step."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32ed2YIHrFHK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "15a43e60-e8bb-4d1a-9e88-aed28d2c2463"
      },
      "source": [
        "#if trained in same session else use checkpoint variable\n",
        "#decoder_embedding_matrix = tf.train.load_variable(checkpointdir, 'decoderNetwork/decoder_embedding/embeddings/.ATTRIBUTES/VARIABLE_VALUE')\n",
        "decoder_embedding_matrix = decoderNetwork.decoder_embedding.variables[0] \n",
        "print(decoderNetwork.decoder_embedding.variables[0].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2368, 256)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxgKWoQcr7YR"
      },
      "source": [
        "\n",
        "if restoring from checkpoint, lets print all variables related to decoder_embeddings and then select and load the right variable containing decoder embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFOylGYTr-74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "183bf225-ee3f-4e04-ea05-11c6f1fa1572"
      },
      "source": [
        "[print(var) for var in tf.train.list_variables(\n",
        "    checkpointdir) if re.match(r'.*decoder_embedding.*',var[0])]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('decoderNetwork/decoder_embedding/embeddings/.ATTRIBUTES/VARIABLE_VALUE', [2368, 256])\n",
            "('decoderNetwork/decoder_embedding/embeddings/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE', [2368, 256])\n",
            "('decoderNetwork/decoder_embedding/embeddings/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE', [2368, 256])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[None, None, None]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4gRwfzSsO_5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "17352d24-c74a-479b-d66e-70a2d76f3c50"
      },
      "source": [
        "decoder_embedding_matrix = tf.train.load_variable(\n",
        "    checkpointdir, 'decoderNetwork/decoder_embedding/embeddings/.ATTRIBUTES/VARIABLE_VALUE')\n",
        "print(decoder_embedding_matrix.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2368, 256)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aw23EgW-sS9y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "outputId": "f8aa0b30-4017-43a2-c2c9-46ed9abb3607"
      },
      "source": [
        "#use with scope /cpu:0 for inferencing\n",
        "#restore from latest checkpoint for inferencing\n",
        "input_raw=\"Hi  \\nHow are you today\"\n",
        "#input_raw=\"Wow!\"  #checking translation on training set record\n",
        "#def inference(input_raw):\n",
        "input_lines = input_raw.split(\"\\n\")\n",
        "# We have a transcript file containing English-Hindi pairs\n",
        "# Preprocess X\n",
        "input_lines = [preprocess_sentence(line) for line in input_lines]\n",
        "input_sequences = [[X_tokenizer.word_index[w] for w in line.split(' ')] for line in input_lines]\n",
        "input_sequences = tf.keras.preprocessing.sequence.pad_sequences(input_sequences,\n",
        "                                                                maxlen=Tx, padding='post')\n",
        "inp = tf.convert_to_tensor(input_sequences)\n",
        "#print(inp.shape)\n",
        "inference_batch_size = input_sequences.shape[0]\n",
        "encoder_initial_cell_state = [tf.zeros((inference_batch_size, rnn_units)),\n",
        "                              tf.zeros((inference_batch_size, rnn_units))]\n",
        "encoder_emb_inp = encoderNetwork.encoder_embedding(inp)\n",
        "a, a_tx, c_tx = encoderNetwork.encoder_rnnlayer(encoder_emb_inp,\n",
        "                                                initial_state =encoder_initial_cell_state)\n",
        "\n",
        "\n",
        "#output_sequences = []\n",
        "print('a_tx :',a_tx.shape)\n",
        "print('c_tx :', c_tx.shape)\n",
        "\n",
        "\n",
        "\n",
        "start_tokens = tf.fill([inference_batch_size],Y_tokenizer.word_index['<start>'])\n",
        "#print(start_tokens)\n",
        "end_token = Y_tokenizer.word_index['<end>']\n",
        "\n",
        "greedy_sampler = tfa.seq2seq.GreedyEmbeddingSampler()\n",
        "#finished,start_inputs = greedy_sampler.initialize(decoder_embedding_matrix,start_tokens,end_token)\n",
        "#print(finished.shape, start_inputs.shape)\n",
        "\n",
        "decoder_input = tf.expand_dims([Y_tokenizer.word_index['<start>']]* inference_batch_size,1)\n",
        "decoder_emb_inp = decoderNetwork.decoder_embedding(decoder_input)\n",
        "\n",
        "decoder_instance = tfa.seq2seq.BasicDecoder(cell = decoderNetwork.rnn_cell, sampler = greedy_sampler,\n",
        "                                            output_layer=decoderNetwork.dense_layer)\n",
        "decoderNetwork.attention_mechanism.setup_memory(a)\n",
        "#pass [ last step activations , encoder memory_state ] as input to decoder for LSTM\n",
        "print(\"decoder_initial_state = [a_tx, c_tx] :\",np.array([a_tx, c_tx]).shape)\n",
        "decoder_initial_state = decoderNetwork.build_decoder_initial_state(inference_batch_size,\n",
        "                                                                   encoder_state=[a_tx, c_tx],\n",
        "                                                                   Dtype=tf.float32)\n",
        "print(\"\\nCompared to simple encoder-decoder without attention, the decoder_initial_state \\\n",
        " is an AttentionWrapperState object containing s_prev tensors and context and alignment vector \\n \")\n",
        "print(\"decoder initial state shape :\",np.array(decoder_initial_state).shape)\n",
        "print(\"decoder_initial_state tensor \\n\", decoder_initial_state)\n",
        "\n",
        "# Since we do not know the target sequence lengths in advance, we use maximum_iterations to limit the translation lengths.\n",
        "# One heuristic is to decode up to two times the source sentence lengths.\n",
        "maximum_iterations = tf.round(tf.reduce_max(Tx) * 2)\n",
        "\n",
        "#initialize inference decoder\n",
        "\n",
        "(first_finished, first_inputs,first_state) = decoder_instance.initialize(decoder_embedding_matrix,\n",
        "                             start_tokens = start_tokens,\n",
        "                             end_token=end_token,\n",
        "                             initial_state = decoder_initial_state)\n",
        "#print( first_finished.shape)\n",
        "print(\"\\nfirst_inputs returns the same decoder_input i.e. embedding of  <start> :\",first_inputs.shape)\n",
        "print(\"start_index_emb_avg \", tf.reduce_sum(tf.reduce_mean(first_inputs, axis=0))) # mean along the batch\n",
        "\n",
        "inputs = first_inputs\n",
        "state = first_state  \n",
        "predictions = np.empty((inference_batch_size,0), dtype = np.int32)                                                                             \n",
        "for j in range(maximum_iterations):\n",
        "    outputs, next_state, next_inputs, finished = decoder_instance.step(j,inputs,state)\n",
        "    inputs = next_inputs\n",
        "    state = next_state\n",
        "    outputs = np.expand_dims(outputs.sample_id,axis = -1)\n",
        "    predictions = np.append(predictions, outputs, axis = -1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a_tx : (2, 1024)\n",
            "c_tx : (2, 1024)\n",
            "decoder_initial_state = [a_tx, c_tx] : (2, 2, 1024)\n",
            "\n",
            "Compared to simple encoder-decoder without attention, the decoder_initial_state  is an AttentionWrapperState object containing s_prev tensors and context and alignment vector \n",
            " \n",
            "decoder initial state shape : (6,)\n",
            "decoder_initial_state tensor \n",
            " AttentionWrapperState(cell_state=[<tf.Tensor: shape=(2, 1024), dtype=float32, numpy=\n",
            "array([[ 0.00262722, -0.05180002,  0.19637935, ...,  0.07058783,\n",
            "        -0.15752116,  0.21294264],\n",
            "       [ 0.03040351, -0.01584375, -0.05175677, ...,  0.00634999,\n",
            "        -0.01663708,  0.14155164]], dtype=float32)>, <tf.Tensor: shape=(2, 1024), dtype=float32, numpy=\n",
            "array([[ 0.00722833, -0.13565895,  0.39125592, ...,  0.12173729,\n",
            "        -0.25489613,  0.58974814],\n",
            "       [ 0.05071958, -0.03602066, -0.1865141 , ...,  0.01743287,\n",
            "        -0.03578758,  0.33205456]], dtype=float32)>], attention=<tf.Tensor: shape=(2, 1024), dtype=float32, numpy=\n",
            "array([[0., 0., 0., ..., 0., 0., 0.],\n",
            "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>, time=<tf.Tensor: shape=(), dtype=int32, numpy=0>, alignments=<tf.Tensor: shape=(2, 8), dtype=float32, numpy=\n",
            "array([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)>, alignment_history=(), attention_state=<tf.Tensor: shape=(2, 8), dtype=float32, numpy=\n",
            "array([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)>)\n",
            "\n",
            "first_inputs returns the same decoder_input i.e. embedding of  <start> : (2, 256)\n",
            "start_index_emb_avg  tf.Tensor(1.3523595, shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzkPUwd6sj9Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "outputId": "f7912f5b-ccc8-43f9-f83f-644e404038a9"
      },
      "source": [
        "print(\"English Sentence:\")\n",
        "print(input_raw)\n",
        "print(\"\\nFrench Translation:\")\n",
        "for i in range(len(predictions)):\n",
        "    line = predictions[i,:]\n",
        "    seq = list(itertools.takewhile( lambda index: index !=2, line))\n",
        "    print(\" \".join( [Y_tokenizer.index_word[w] for w in seq]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "English Sentence:\n",
            "Hi  \n",
            "How are you today\n",
            "\n",
            "French Translation:\n",
            "salut .\n",
            "etes vous sympa .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2lAKmFusohi"
      },
      "source": [
        "Inference using Beam Search with beam_width = 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWpn4bH4sr9J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "outputId": "e09b6513-45b0-4f13-c916-a4527b332583"
      },
      "source": [
        "beam_width = 3\n",
        "#use with scope /cpu:0 for inferencing\n",
        "#restore from latest checkpoint for inferencing\n",
        "input_raw=\"Hi  \\nHow are you today\"\n",
        "#input_raw=\"Wow!\"  #checking translation on training set record\n",
        "#def inference(input_raw):\n",
        "input_lines = input_raw.split(\"\\n\")\n",
        "# We have a transcript file containing English-Hindi pairs\n",
        "# Preprocess X\n",
        "input_lines = [preprocess_sentence(line) for line in input_lines]\n",
        "input_sequences = [[X_tokenizer.word_index[w] for w in line.split(' ')] for line in input_lines]\n",
        "input_sequences = tf.keras.preprocessing.sequence.pad_sequences(input_sequences,\n",
        "                                                                maxlen=Tx, padding='post')\n",
        "inp = tf.convert_to_tensor(input_sequences)\n",
        "#print(inp.shape)\n",
        "inference_batch_size = input_sequences.shape[0]\n",
        "encoder_initial_cell_state = [tf.zeros((inference_batch_size, rnn_units)),\n",
        "                              tf.zeros((inference_batch_size, rnn_units))]\n",
        "encoder_emb_inp = encoderNetwork.encoder_embedding(inp)\n",
        "a, a_tx, c_tx = encoderNetwork.encoder_rnnlayer(encoder_emb_inp,\n",
        "                                                initial_state =encoder_initial_cell_state)\n",
        "\n",
        "start_tokens = tf.fill([inference_batch_size],Y_tokenizer.word_index['<start>'])\n",
        "#print(start_tokens)\n",
        "end_token = Y_tokenizer.word_index['<end>']\n",
        "\n",
        "\n",
        "\n",
        "decoder_input = tf.expand_dims([Y_tokenizer.word_index['<start>']]* inference_batch_size,1)\n",
        "decoder_emb_inp = decoderNetwork.decoder_embedding(decoder_input)\n",
        "\n",
        "\n",
        "#From official documentation\n",
        "#NOTE If you are using the BeamSearchDecoder with a cell wrapped in AttentionWrapper, then you must ensure that:\n",
        "\n",
        "#The encoder output has been tiled to beam_width via tfa.seq2seq.tile_batch (NOT tf.tile).\n",
        "#The batch_size argument passed to the get_initial_state method of this wrapper is equal to true_batch_size * beam_width.\n",
        "#The initial state created with get_initial_state above contains a cell_state value containing properly tiled final state from the encoder.\n",
        "encoder_memory = tfa.seq2seq.tile_batch(a, beam_width)\n",
        "decoderNetwork.attention_mechanism.setup_memory(encoder_memory)\n",
        "print(\"beam_with * [batch_size, Tx, rnn_units] :  3 * [2, Tx, rnn_units]] :\", encoder_memory.shape)\n",
        "#set decoder_inital_state which is an AttentionWrapperState considering beam_width\n",
        "decoder_initial_state = decoderNetwork.rnn_cell.get_initial_state(batch_size = inference_batch_size* beam_width,dtype = Dtype)\n",
        "encoder_state = tfa.seq2seq.tile_batch([a_tx, c_tx], multiplier=beam_width)\n",
        "decoder_initial_state = decoder_initial_state.clone(cell_state=encoder_state) \n",
        "\n",
        "decoder_instance = tfa.seq2seq.BeamSearchDecoder(decoderNetwork.rnn_cell,beam_width=beam_width,\n",
        "                                                 output_layer=decoderNetwork.dense_layer)\n",
        "\n",
        "\n",
        "# Since we do not know the target sequence lengths in advance, we use maximum_iterations to limit the translation lengths.\n",
        "# One heuristic is to decode up to two times the source sentence lengths.\n",
        "maximum_iterations = tf.round(tf.reduce_max(Tx) * 2)\n",
        "\n",
        "#initialize inference decoder\n",
        "\n",
        "(first_finished, first_inputs,first_state) = decoder_instance.initialize(decoder_embedding_matrix,\n",
        "                             start_tokens = start_tokens,\n",
        "                             end_token=end_token,\n",
        "                             initial_state = decoder_initial_state)\n",
        "#print( first_finished.shape)\n",
        "print(\"\\nfirst_inputs returns the same decoder_input i.e. embedding of  <start> :\",first_inputs.shape)\n",
        "\n",
        "inputs = first_inputs\n",
        "state = first_state  \n",
        "predictions = np.empty((inference_batch_size, beam_width,0), dtype = np.int32)\n",
        "beam_scores =  np.empty((inference_batch_size, beam_width,0), dtype = np.float32)                                                                            \n",
        "for j in range(maximum_iterations):\n",
        "    beam_search_outputs, next_state, next_inputs, finished = decoder_instance.step(j,inputs,state)\n",
        "    inputs = next_inputs\n",
        "    state = next_state\n",
        "    outputs = np.expand_dims(beam_search_outputs.predicted_ids,axis = -1)\n",
        "    scores = np.expand_dims(beam_search_outputs.scores,axis = -1)\n",
        "    predictions = np.append(predictions, outputs, axis = -1)\n",
        "    beam_scores = np.append(beam_scores, scores, axis = -1)\n",
        "print(predictions.shape) \n",
        "print(beam_scores.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "beam_with * [batch_size, Tx, rnn_units] :  3 * [2, Tx, rnn_units]] : (6, 8, 1024)\n",
            "\n",
            "first_inputs returns the same decoder_input i.e. embedding of  <start> : (2, 3, 256)\n",
            "(2, 3, 16)\n",
            "(2, 3, 16)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YC5YFInotFpB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        },
        "outputId": "f02016ef-a947-471e-8f76-bc645d9cb4e2"
      },
      "source": [
        "print(\"-----------------\")\n",
        "print(\"English Sentence:\")\n",
        "print(input_raw)\n",
        "print(\"-----------------\")\n",
        "print(\"\\nFrench Translation:\")\n",
        "for i in range(len(predictions)):\n",
        "    print(\"---------------------------------------------\")\n",
        "    output_beams_per_sample = predictions[i,:,:]\n",
        "    score_beams_per_sample = beam_scores[i,:,:]\n",
        "    for beam, score in zip(output_beams_per_sample,score_beams_per_sample) :\n",
        "        seq = list(itertools.takewhile( lambda index: index !=2, beam))\n",
        "        score_indexes = np.arange(len(seq))\n",
        "        beam_score = score[score_indexes].sum()\n",
        "        print(\" \".join( [Y_tokenizer.index_word[w] for w in seq]), \" beam score: \", beam_score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-----------------\n",
            "English Sentence:\n",
            "Hi  \n",
            "How are you today\n",
            "-----------------\n",
            "\n",
            "French Translation:\n",
            "---------------------------------------------\n",
            "salut .  beam score:  -1.5015447\n",
            "bonjour !  beam score:  -4.138088\n",
            "magnifique derriere l bienvenu !  beam score:  -23.313568\n",
            "---------------------------------------------\n",
            "etes vous sympa .  beam score:  -8.85964\n",
            "comportez vous sympa .  beam score:  -10.948074\n",
            "sont vous dans nouveau .  beam score:  -18.923452\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUxTeRj0tRxp"
      },
      "source": [
        "Evaluate Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gjv3DqTtT_Z"
      },
      "source": [
        "def eval_step(input_batch, output_batch,encoder_initial_cell_state, BATCH_SIZE):\n",
        "    #initialize loss = 0\n",
        "    loss = 0\n",
        "\n",
        "    # we can do initialization in outer block\n",
        "    #encoder_initial_cell_state = encoder.initialize_initial_state()\n",
        "    encoder_emb_inp = encoderNetwork.encoder_embedding(input_batch)\n",
        "    a, h_tx, c_tx = encoderNetwork.encoder_rnnlayer(encoder_emb_inp, \n",
        "                                                    initial_state =encoder_initial_cell_state)\n",
        "\n",
        "\n",
        "\n",
        "    decoder_input = output_batch[:,:-1] # ignore <end>\n",
        "    #compare logits with timestepped +1 version of decoder_input\n",
        "    decoder_output = output_batch[:,1:] #ignore <start>\n",
        "    decoder_emb_inp = decoderNetwork.decoder_embedding(decoder_input)\n",
        "    decoder_instance = tfa.seq2seq.BasicDecoder(decoderNetwork.rnn_cell, \n",
        "                                                greedy_sampler,\n",
        "                                                decoderNetwork.dense_layer)\n",
        "    #BasicDecoderOutput\n",
        "\n",
        "    decoderNetwork.attention_mechanism.setup_memory(a)\n",
        "    #pass [ last step activations , encoder memory_state ] as input to decoder for LSTM\n",
        "    \n",
        "    decoder_initial_state = decoderNetwork.build_decoder_initial_state(BATCH_SIZE,\n",
        "                                                                       encoder_state=[h_tx, c_tx],\n",
        "                                                                       Dtype=tf.float32)\n",
        "    outputs, _, _ = decoderNetwork.decoder(decoder_emb_inp,initial_state=decoder_initial_state,\n",
        "                                           sequence_length=BATCH_SIZE*[Ty-1])\n",
        "    logits = outputs.rnn_output\n",
        "    sample_id = outputs.sample_id\n",
        "    #Calculate loss\n",
        "    loss = loss_function(logits, decoder_output)\n",
        "    return loss, sample_id"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shxbUvXvtWfa"
      },
      "source": [
        "Evaluation Loss on Entire Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8997BY-tZk6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8bc06af5-f992-4b73-d159-ac56bfc53d8d"
      },
      "source": [
        "dataset_test = tf.data.Dataset.from_tensor_slices((X_test, Y_test)).batch(len(X_test))\n",
        "for (input_batch, output_batch) in dataset_test.take(-1):\n",
        "    batch_size = len(input_batch)\n",
        "    print(input_batch.shape)\n",
        "    encoder_initial_cell_state = [tf.zeros((batch_size, rnn_units)),\n",
        "                                  tf.zeros((batch_size, rnn_units))]\n",
        "    loss,_ = eval_step(input_batch, output_batch, encoder_initial_cell_state, batch_size)\n",
        "    loss = tf.reduce_mean(loss)\n",
        "    print(\"Training loss {}\".format(loss) )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1000, 8)\n",
            "Training loss 1.0249402523040771\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxzkBidYteyR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "25f96b19-ead0-4550-bdc9-fbb2ea17e671"
      },
      "source": [
        "#BasicDecoder initialization returns the <start> sequence as first_input\n",
        "#Check Inference Cell output\n",
        "\n",
        "start_index = Y_tokenizer.word_index['<start>']\n",
        "start_index = tf.constant([start_index], dtype = tf.int32)\n",
        "print(start_index)\n",
        "start_index_emb = decoderNetwork.decoder_embedding(start_index)\n",
        "print(start_index_emb.shape)\n",
        "start_index_emb_avg = tf.reduce_sum(start_index_emb)\n",
        "print(start_index_emb_avg.numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([1], shape=(1,), dtype=int32)\n",
            "(1, 256)\n",
            "1.3521259\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}