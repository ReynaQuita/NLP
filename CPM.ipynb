{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    },
    "colab": {
      "name": "prediction_v2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ReynaQuita/NLP/blob/main/CPM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIGuVr9pi8Ns"
      },
      "source": [
        "# !pip install -U tensorflow tensorflow-hub"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WsAmNMJi8Nu",
        "outputId": "ec9d9981-20b1-45b3-b524-d492d290c0ff"
      },
      "source": [
        "# 依赖：\n",
        "!pip install sentencepiece\n",
        "!pip install jieba\n",
        "!pip install regex\n",
        "!pip install tensorflow\n",
        "!pip install tensorflow-hub"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 4.0MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.95\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.7/dist-packages (0.42.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (2019.12.20)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.5.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.12.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.12.4)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: grpcio~=1.34.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.34.1)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.36.2)\n",
            "Requirement already satisfied: keras-nightly~=2.5.0.dev in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.5.0.dev2021032900)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.7.4.3)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.19.5)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (1.30.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (3.3.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (57.0.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (0.4.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (1.8.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (4.2.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (4.7.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow) (4.0.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (2.10)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.5->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow) (3.1.0)\n",
            "Requirement already satisfied: tensorflow-hub in /usr/local/lib/python3.7/dist-packages (0.12.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-hub) (3.12.4)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-hub) (1.19.5)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorflow-hub) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorflow-hub) (57.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfhPy3jhku6_",
        "outputId": "8b4fa44b-2014-4c63-f8e3-cba4919de12d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "aSSQWuEljXGY",
        "outputId": "edbffb01-af31-40d5-a7cb-11ee7be7d0c3"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "src = list(files.upload().values())[0]\n",
        "# open('mylib.py','wb').write(src)\n",
        "# import mylib"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-db2ec1bb-b5fb-40c3-8d27-24fd5f8ad6a4\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-db2ec1bb-b5fb-40c3-8d27-24fd5f8ad6a4\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving gpt2_tokenizer.py to gpt2_tokenizer.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LsDthDoi8Nv"
      },
      "source": [
        "import tensorflow_hub as hub\n",
        "import tensorflow as tf\n",
        "\n",
        "from gpt2_tokenizer import GPT2Tokenizer"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7wrFbNixi8Nw",
        "outputId": "967f9caf-fd86-4a66-e399-6a550f0203d9"
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xo1ptj4i8Nw",
        "outputId": "89ac1f50-9f84-4bfb-cb77-e819bcdf635f"
      },
      "source": [
        "print(hub.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.12.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NtSqlZji8Nx"
      },
      "source": [
        "tokenizer = GPT2Tokenizer(\n",
        "    '/content/drive/MyDrive/Colab Notebooks/cpm-tf2/CPM-Generate/bpe_3w_new/vocab.json',\n",
        "    '/content/drive/MyDrive/Colab Notebooks/cpm-tf2/CPM-Generate/bpe_3w_new/merges.txt',\n",
        "    model_file='/content/drive/MyDrive/Colab Notebooks/cpm-tf2/CPM-Generate/bpe_3w_new/chinese_vocab.model')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEO8fLnyi8Nx"
      },
      "source": [
        "gpt = hub.load('/content/drive/MyDrive/Colab Notebooks/cpm-tf2/cpm-lm-tf2_v2/')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SeDw0NpFi8Ny"
      },
      "source": [
        "def sample(tokenizer, gpt, sentence, number=1, length=20, top_p=0.9, temperature=0.9):\n",
        "    \"\"\"\n",
        "    numbert: 输出句子个数 (number of output sentence)\n",
        "    length: 输出最大长度\n",
        "    top_p: token的概率排在这以上才有效\n",
        "    temperature: 温度\n",
        "    \"\"\"\n",
        "    inputs = tf.constant([tokenizer.encode(sentence)] * number, dtype=tf.int64)\n",
        "    length = tf.constant(length, dtype=tf.int64)\n",
        "    ret = gpt.signatures['serving_default'](\n",
        "        inp=inputs,\n",
        "        length=length,\n",
        "        top_p=tf.constant(top_p, tf.float32),\n",
        "        temperature=tf.constant(temperature, tf.float32)\n",
        "    )['output_0']\n",
        "    return [\n",
        "        tokenizer.decode(s).replace(' ', '')\n",
        "        for s in ret.numpy()\n",
        "    ]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TNhADpvi8Ny"
      },
      "source": [
        "# 问答例子 (Question-Answering)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2wtHGrNi8Ny"
      },
      "source": [
        "def ask_gpt(question):\n",
        "    q = f'''\n",
        "问题：中国首都是哪里？\n",
        "答案：北京\n",
        "问题：美国的首都是哪里？\n",
        "答案：华盛顿\n",
        "问题：李白在哪个朝代？\n",
        "答案：唐朝\n",
        "问题：{question}\n",
        "答案：'''\n",
        "    ret = sample(tokenizer, gpt, q, 3, 10, top_p=0.9, temperature=0.9)\n",
        "    answers = []\n",
        "    for x in ret:\n",
        "        a = x[len(q):]\n",
        "        a = a.split('\\n')[0]\n",
        "        answers.append(a)\n",
        "    return answers"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLwoXgQki8Nz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0300e840-5e7f-4677-ad32-2cb5060ea130"
      },
      "source": [
        "ask_gpt('唐伯虎是哪个朝代的人？')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building prefix dict from the default dictionary ...\n",
            "Dumping model to file cache /tmp/jieba.cache\n",
            "Loading model cost 0.791 seconds.\n",
            "Prefix dict has been built successfully.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['清朝', '明朝', '明朝']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAUiqom1i8Nz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b63c2739-e2f1-4ae3-9734-01b1e266bd8e"
      },
      "source": [
        "ask_gpt('世界上最帅的是谁？')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['头文字D中的藤原拓海', '普京', '普京']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vWtSNZ4i8Nz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1dca1b76-d7ae-4164-f8d1-eecee9aa5523"
      },
      "source": [
        "ask_gpt('世界上最聪明的人是谁？')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['尼古拉·特斯拉', '爱迪生', '比尔盖茨']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vA9r12Vi8N0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07316abc-b455-45ee-acb0-2d9fc352b343"
      },
      "source": [
        "ask_gpt('李清照是哪个朝代的人？')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['宋代', '宋代', '北宋']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNOon6v3i8N0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcd4e127-e4f8-45ab-aa57-8ac93068f68b"
      },
      "source": [
        "ask_gpt('关公和秦琼谁厉害？')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['关羽和张飞谁厉害?', '两个都是神人', '关公']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_O7gBQA_i8N0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e40f4bd-2c1c-481b-be56-7c3fdd008074"
      },
      "source": [
        "ask_gpt('如何赚一百万美元？')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['卖菜', '炒股', '卖菜']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dB2mPN8bi8N1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f05f7065-5eaf-4de8-9123-02efd0816085"
      },
      "source": [
        "ask_gpt('烧烤和火锅哪个好吃？')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['烤肉', '烤羊肉串', '不知道']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBk9p0Pri8N1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "144f987a-7be6-4d99-9ff6-809d48e393e6"
      },
      "source": [
        "ask_gpt('如何成为老师？')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['老师是一种职业', '老师是什么?', '认真读书,听老师的话']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9Nzrpo_i8N1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b39f6ded-9d6f-4540-c338-543699db6311"
      },
      "source": [
        "ask_gpt('佩奇是什么动物？')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['浣熊', '浣熊', '鳄鱼']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YrTITu_i8N1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a37f4d4e-f0e8-4485-bc86-3cd1f7f1f5cf"
      },
      "source": [
        "ask_gpt('大象有几条腿？')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['象腿', '八条腿', '它是两条腿']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqrgQuHki8N2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a41b5f7-8560-4654-f74d-f1450b0105a2"
      },
      "source": [
        "ask_gpt('姚明有多高？')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['203cm', '1米72', '1米74']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWpFqcALi8N2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26de6f3e-ce72-4091-9fca-cdf98ae84f0b"
      },
      "source": [
        "ask_gpt('汤姆和杰瑞谁厉害？')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['汤姆', '杰瑞', 'Tom和Jerry']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfG_nOJ_i8N2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d83a3e50-0201-4dad-ddd6-3d628c2bf33e"
      },
      "source": [
        "ask_gpt('野原新之助能打过樱桃子吗？')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['没有', '能', '不知道']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hoW5om_qi8N2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b32fa827-cf69-4b03-bf0b-e9e2c8db7a3d"
      },
      "source": [
        "ask_gpt('学音乐和学画画哪个好？')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['两者都很好', '都好', '都不好']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8JQaG0Oi8N3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f52cc63-991d-48e9-85e9-30084d207235"
      },
      "source": [
        "ask_gpt('中文和英文哪个难学？')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['中文', '英文', '中文']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccJIAno8i8N3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "324a5ddf-7bcb-44cf-f33a-939ca5abb568"
      },
      "source": [
        "ask_gpt('python和java哪个难？')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Java', 'c&java', 'Java']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTA7NtOYi8N3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e117c682-aae1-4e4d-a986-60a135f411c7"
      },
      "source": [
        "ask_gpt('“锄禾日当午”的下一句是什么？')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['大年初一', '“汗滴禾下土”', '“汗滴禾下土”']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEwB-UJdi8N3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48804c3b-f8d6-44ef-ef1f-eca53edbeb49"
      },
      "source": [
        "ask_gpt('烤鸭的主要原料是什么？')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['鸭肉', '鸭子', '鸭']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLvvqKumi8N4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f31d032a-5fe1-4d29-9240-cecae0ec65f1"
      },
      "source": [
        "ask_gpt('把大象放冰箱总共分几步？')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['第一步:首先,放进', '第一步:先把大象放进冰箱,', '第一步:打开冰箱门,把大象']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Je1osfyEi8N4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "456b852e-16b1-4bd2-efa6-3d300cf106a9"
      },
      "source": [
        "ask_gpt('珠穆朗玛峰有多高？')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['1088米', '8848米', '4200米']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s75Gz1cgi8N4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9397d715-457c-42ce-d5de-f851040b5ba5"
      },
      "source": [
        "ask_gpt('世界上最高的山是什么？')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['珠穆朗玛峰', '珠穆朗玛峰', '珠穆朗玛峰']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-mutBh1i8N4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8277b1df-15ff-479c-ab71-d44795987a4e"
      },
      "source": [
        "ask_gpt('中国有多少人？')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['中国有7500万', '一千多万', '100万人']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfGABl5hi8N5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfead1a6-a0ff-4b46-90f4-edd4859fd44e"
      },
      "source": [
        "ask_gpt('日本有多少人？')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['249万', '409', '只有两万人']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5GKBWuSi8N5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf925126-ddd9-43c6-c636-6af56eb0e026"
      },
      "source": [
        "ask_gpt('苹果手机好还是华为手机好？')"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['苹果', '苹果', '“你懂的”']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j00KHwFQi8N5"
      },
      "source": [
        "# 推理 (Reasoning)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VX09Mbyi8N5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58bffbcd-f5f6-44c0-932a-ce61f326856d"
      },
      "source": [
        "ret = sample(tokenizer, gpt, '小明决定去吃饭，小红继续写作业\\n问题：去吃饭的人是谁？\\n答案：', 3, 10, top_p=0.9, temperature=0.9)\n",
        "for x in ret:\n",
        "    print(x)\n",
        "    print('-' * 20)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "小明决定去吃饭,小红继续写作业\n",
            "问题:去吃饭的人是谁?\n",
            "答案:小红。\n",
            "解析:第4题\n",
            "--------------------\n",
            "小明决定去吃饭,小红继续写作业\n",
            "问题:去吃饭的人是谁?\n",
            "答案:我\n",
            "小红:看!\n",
            "小明\n",
            "--------------------\n",
            "小明决定去吃饭,小红继续写作业\n",
            "问题:去吃饭的人是谁?\n",
            "答案:小明,小红\n",
            "【精彩片段\n",
            "--------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6eAoN_o-i8N6"
      },
      "source": [
        "# 英文问答例子 (English Entity Generation)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msY4CMRIi8N6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7de8515-361d-4126-bb8b-c02f68592592"
      },
      "source": [
        "ret = sample(tokenizer, gpt, '默写英文：\\n狗dog\\n猫cat\\n鸟', 3, 10, top_p=0.9, temperature=0.9)\n",
        "for x in ret:\n",
        "    print(x)\n",
        "    print('-' * 20)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "默写英文:\n",
            "狗dog\n",
            "猫cat\n",
            "鸟bird\n",
            "猫头鹰crow\n",
            "--------------------\n",
            "默写英文:\n",
            "狗dog\n",
            "猫cat\n",
            "鸟bird\n",
            "鱼tao\n",
            "飞\n",
            "--------------------\n",
            "默写英文:\n",
            "狗dog\n",
            "猫cat\n",
            "鸟bird\n",
            "洋娃娃ballet\n",
            "--------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3iTYNJz9i8N6"
      },
      "source": [
        "# 默写古诗例子 (Chinese Poems LM)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mufT0mV9i8N6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a969521b-98a3-48ab-fe7e-1958d85e5ba4"
      },
      "source": [
        "ret = sample(tokenizer, gpt, '默写古诗：\\n白日依山尽，黄河入海流。\\n床前明月光，', 3, 10, top_p=0.9, temperature=0.9)\n",
        "for x in ret:\n",
        "    print(x)\n",
        "    print('-' * 20)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "默写古诗:\n",
            "白日依山尽,黄河入海流。\n",
            "床前明月光,疑是地上霜。\n",
            "举头望\n",
            "--------------------\n",
            "默写古诗:\n",
            "白日依山尽,黄河入海流。\n",
            "床前明月光,疑是地上霜。\n",
            "举头望\n",
            "--------------------\n",
            "默写古诗:\n",
            "白日依山尽,黄河入海流。\n",
            "床前明月光,疑是地上霜。\n",
            "举头望\n",
            "--------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6PXfdrmi8N7"
      },
      "source": [
        "# 不同的角色对话生成例子 (Dialogue Generation)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPIcKVJfi8N7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8f6a239-711f-44c7-9f66-2ad88bd4ed17"
      },
      "source": [
        "ret = sample(tokenizer, gpt, '李大嘴：“各回各家，各找各妈！” \\n佟掌柜：“', 3, 20, top_p=0.9, temperature=0.9)\n",
        "for x in ret:\n",
        "    print(x)\n",
        "    print('-' * 20)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "李大嘴:“各回各家,各找各妈!”\n",
            "佟掌柜:“这位少爷,你也是个买卖人,得给咱几个\n",
            "--------------------\n",
            "李大嘴:“各回各家,各找各妈!”\n",
            "佟掌柜:“刘麻子,你也该出来了,这破地方我也受够了\n",
            "--------------------\n",
            "李大嘴:“各回各家,各找各妈!”\n",
            "佟掌柜:“怎么,还有脸回?”\n",
            "燕小六:“\n",
            "--------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Ky15pCIi8N7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c65dd3c3-e8bd-4a46-8f0a-c0c4444b5d5a"
      },
      "source": [
        "ret = sample(tokenizer, gpt, '李大嘴：“各回各家，各找各妈！” \\n白展堂：“', 3, 20, top_p=0.9, temperature=0.9)\n",
        "for x in ret:\n",
        "    print(x)\n",
        "    print('-' * 20)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "李大嘴:“各回各家,各找各妈!”\n",
            "白展堂:“白大哥,你要跑就走吧,我不拦你。”\n",
            "--------------------\n",
            "李大嘴:“各回各家,各找各妈!”\n",
            "白展堂:“你这是怎么了?”\n",
            "包不同:“各回各家\n",
            "--------------------\n",
            "李大嘴:“各回各家,各找各妈!”\n",
            "白展堂:“你们以后不要再见面了,这件事我真的帮不了你。”\n",
            "--------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMq3tixri8N7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "822b2f37-c321-49a3-ac50-c6a823f14c2f"
      },
      "source": [
        "ret = sample(tokenizer, gpt, '李大嘴：“各回各家，各找各妈！” \\n莫小贝：“', 3, 20, top_p=0.9, temperature=0.9)\n",
        "for x in ret:\n",
        "    print(x)\n",
        "    print('-' * 20)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "李大嘴:“各回各家,各找各妈!”\n",
            "莫小贝:“我等了你六年!”\n",
            "韦小宝:“等了\n",
            "--------------------\n",
            "李大嘴:“各回各家,各找各妈!”\n",
            "莫小贝:“我跟你有仇,我⁇你妈。”\n",
            "莫\n",
            "--------------------\n",
            "李大嘴:“各回各家,各找各妈!”\n",
            "莫小贝:“师父,我做梦也没想到,有人会那么对我。\n",
            "--------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTIb80N4i8N8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72ed8af2-99d4-4d3d-aa95-519f71e8e95e"
      },
      "source": [
        "ret = sample(tokenizer, gpt, '李大嘴：“各回各家，各找各妈！” \\n李白：“', 3, 20, top_p=0.9, temperature=0.9)\n",
        "for x in ret:\n",
        "    print(x)\n",
        "    print('-' * 20)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "李大嘴:“各回各家,各找各妈!”\n",
            "李白:“你们几个小年轻儿,不懂事,一窝蜂的上,上\n",
            "--------------------\n",
            "李大嘴:“各回各家,各找各妈!”\n",
            "李白:“我去也!”\n",
            "黄巢:“不想干就滚\n",
            "--------------------\n",
            "李大嘴:“各回各家,各找各妈!”\n",
            "李白:“金鳞岂是池中物,一遇风云便化龙。”\n",
            "--------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYrvnf0ki8N8"
      },
      "source": [
        "# 问答的例子 (Entity Generation)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8wZ2v3ai8N8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fdc7c67-7330-4347-c614-b079324b4b14"
      },
      "source": [
        "ret = sample(tokenizer, gpt, '中国的首都是北京\\n日本的首都是东京\\n美国的首都是', 3, 3, top_p=0.9, temperature=0.9)\n",
        "for x in ret:\n",
        "    print(x)\n",
        "    print('-' * 20)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "中国的首都是北京\n",
            "日本的首都是东京\n",
            "美国的首都是华盛顿\n",
            "法国\n",
            "--------------------\n",
            "中国的首都是北京\n",
            "日本的首都是东京\n",
            "美国的首都是华盛顿\n",
            "韩国\n",
            "--------------------\n",
            "中国的首都是北京\n",
            "日本的首都是东京\n",
            "美国的首都是华盛顿\n",
            "世界\n",
            "--------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXAQusKoi8N8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10e8013e-344f-472c-b141-920a272a7211"
      },
      "source": [
        "ret = sample(tokenizer, gpt, '李白所在朝代是唐\\n李清照所在朝代是宋\\n唐伯虎所在朝代是', 3, 1, top_p=0.9, temperature=0.9)\n",
        "for x in ret:\n",
        "    print(x)\n",
        "    print('-' * 20)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "李白所在朝代是唐\n",
            "李清照所在朝代是宋\n",
            "唐伯虎所在朝代是明\n",
            "--------------------\n",
            "李白所在朝代是唐\n",
            "李清照所在朝代是宋\n",
            "唐伯虎所在朝代是明\n",
            "--------------------\n",
            "李白所在朝代是唐\n",
            "李清照所在朝代是宋\n",
            "唐伯虎所在朝代是明\n",
            "--------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WA2PFbvOi8N9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "550b59ed-2dd5-476f-a72a-fbbdba9530fa"
      },
      "source": [
        "ret = sample(tokenizer, gpt, '陈奕迅是歌星\\n郭德纲是', 3, 1, top_p=0.9, temperature=0.9)\n",
        "for x in ret:\n",
        "    print(x)\n",
        "    print('-' * 20)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "陈奕迅是歌星\n",
            "郭德纲是评书\n",
            "--------------------\n",
            "陈奕迅是歌星\n",
            "郭德纲是相声演员\n",
            "--------------------\n",
            "陈奕迅是歌星\n",
            "郭德纲是相声\n",
            "--------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tp8Jb994i8N9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9507b44-79ae-4655-a373-369b8fc40bc7"
      },
      "source": [
        "ret = sample(tokenizer, gpt, '珠穆朗玛峰的高度（米）是', 3, 10, top_p=0.9, temperature=0.9)\n",
        "for x in ret:\n",
        "    print(x)\n",
        "    print('-' * 20)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "珠穆朗玛峰的高度(米)是13848,而南美洲最高峰—\n",
            "--------------------\n",
            "珠穆朗玛峰的高度(米)是在未开发前3000米(-5000米\n",
            "--------------------\n",
            "珠穆朗玛峰的高度(米)是2346米,仅次于珠穆朗玛\n",
            "--------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SX6EUZoKi8N9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "394143ea-4dec-43c8-8c56-0ccf01bb7da2"
      },
      "source": [
        "ret = sample(tokenizer, gpt, '姚明的身高（米）是', 3, 10, top_p=0.9, temperature=0.9)\n",
        "for x in ret:\n",
        "    print(x)\n",
        "    print('-' * 20)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "姚明的身高(米)是六英尺三英寸,邓肯的身高\n",
            "--------------------\n",
            "姚明的身高(米)是1.75米,\n",
            "--------------------\n",
            "姚明的身高(米)是多少?今天看到福原爱在\n",
            "--------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rkGuN7qi8N9"
      },
      "source": [
        "# 算数例子 (Arithmatic)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sv9k09wJi8N9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27e8dec1-7786-4e1e-e982-1c0ebefd4b4d"
      },
      "source": [
        "ret = sample(tokenizer, gpt, '1+1=2\\n2+2=4\\n3+3=6\\n4+4=', 3, 1, top_p=0.9, temperature=0.9)\n",
        "for x in ret:\n",
        "    print(x)\n",
        "    print('-' * 20)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1+1=2\n",
            "2+2=4\n",
            "3+3=6\n",
            "4+4=12\n",
            "--------------------\n",
            "1+1=2\n",
            "2+2=4\n",
            "3+3=6\n",
            "4+4=8\n",
            "--------------------\n",
            "1+1=2\n",
            "2+2=4\n",
            "3+3=6\n",
            "4+4=12\n",
            "--------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "0fBkE27ki8N-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13b08b78-a75b-46d2-8011-70339b227ef8"
      },
      "source": [
        "ret = sample(tokenizer, gpt, '1+1=2\\n1+2=3\\n1+3=4\\n1+4=', 3, 1, top_p=0.9, temperature=0.9)\n",
        "for x in ret:\n",
        "    print(x)\n",
        "    print('-' * 20)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1+1=2\n",
            "1+2=3\n",
            "1+3=4\n",
            "1+4=5\n",
            "--------------------\n",
            "1+1=2\n",
            "1+2=3\n",
            "1+3=4\n",
            "1+4=5\n",
            "--------------------\n",
            "1+1=2\n",
            "1+2=3\n",
            "1+3=4\n",
            "1+4=5\n",
            "--------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejbtbiEbi8N-"
      },
      "source": [
        "# ???的例子 (Language Modeling)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97RlL5nzi8N-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "545b16ca-a025-444e-922b-ffa725e250d9"
      },
      "source": [
        "ret = sample(tokenizer, gpt, '''惊雷这通天修为\n",
        "天塌地陷紫金锤\n",
        "紫电这玄真火焰\n",
        "''', 3, 30, top_p=0.9, temperature=0.9)\n",
        "for x in ret:\n",
        "    print(x)\n",
        "    print('-' * 20)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "惊雷这通天修为\n",
            "天塌地陷紫金锤\n",
            "紫电这玄真火焰\n",
            "紫金锤火紫金闪\n",
            "八方云动山河动\n",
            "青天白日紫天雷\n",
            "赤云红光九龙\n",
            "--------------------\n",
            "惊雷这通天修为\n",
            "天塌地陷紫金锤\n",
            "紫电这玄真火焰\n",
            "天雷这九天雷劫\n",
            "烈火这九天大劫\n",
            "金光这九天金光\n",
            "金木水火土\n",
            "神雷这\n",
            "--------------------\n",
            "惊雷这通天修为\n",
            "天塌地陷紫金锤\n",
            "紫电这玄真火焰\n",
            "玄元这玄真金\n",
            "金水这玄真木\n",
            "木火两相生\n",
            "战气磅礴灭天\n",
            "--------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfjVy2jki8N-"
      },
      "source": [
        "# 写作文例子 (LM)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIC9sNcbi8N_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75f5216a-27cb-4f52-d444-11d33b267de8"
      },
      "source": [
        "ret = sample(tokenizer, gpt, '''爱情是''', 3, 50, top_p=0.9, temperature=0.9)\n",
        "for x in ret:\n",
        "    print(x)\n",
        "    print('-' * 20)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "爱情是怎么开始的。男:1、在恋爱中会经常说一些类似于“我对你的爱很深”“你是我的女神”“我对你的爱\n",
            "--------------------\n",
            "爱情是不一样的,我怎么确定对方是不是也是这样想的呢?万一错过了对的人,年纪大了怎么办?家里人知道了肯定会难过,自己也会愧疚一辈子。\n",
            "--------------------\n",
            "爱情是一场持久战,男女双方一定要保持自己的姿态,不要被一些不良的想法干扰,合理保持理性,建立一种有你在的爱的气氛,这点很重要。4\n",
            "--------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Jc53lkUi8N_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afca411c-ba4f-42ec-ed13-e7f037a4d9e5"
      },
      "source": [
        "ret = sample(\n",
        "    tokenizer, gpt,\n",
        "    '''一时黛玉进了荣府，下了车。众嬷嬷引着，便往东转弯，穿过一个东西的穿堂，向南大厅之后，仪门内大院落，上面五间大正房，两边厢房鹿顶耳房钻山，四通八达，轩昂壮丽，比贾母处不同。黛玉便知这方是正经正内室，一条大甬路，直接出大门的。''',\n",
        "    3, 200, top_p=0.9, temperature=0.9)\n",
        "for x in ret:\n",
        "    print(x)\n",
        "    print('-' * 20)\n"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "一时黛玉进了荣府,下了车。众嬷嬷引着,便往东转弯,穿过一个东西的穿堂,向南大厅之后,仪门内大院落,上面五间大正房,两边厢房鹿顶耳房钻山,四通八达,轩昂壮丽,比贾母处不同。黛玉便知这方是正经正内室,一条大甬路,直接出大门的。一路向南,至内院花园,穿过两边高墙,便到后院了。只见一簇柏树,大约八九十棵,都是三四百年以上的古柏,槎丫交柯,郁郁苍苍,不⁇壮观。又看过东南屋后,有一座园子,大约有一亩空地,四面俱是树木,中间是个长方池子,四周都是花圃,种着奇花异草,也有桂花、海棠、苹果、杏子、樱桃之类,上面架着数架白玉栏杆,中间是个夹道的池塘,水边有一座石桥,池中浮着数尾鲤鱼,——“泉声”。想必是\n",
            "--------------------\n",
            "一时黛玉进了荣府,下了车。众嬷嬷引着,便往东转弯,穿过一个东西的穿堂,向南大厅之后,仪门内大院落,上面五间大正房,两边厢房鹿顶耳房钻山,四通八达,轩昂壮丽,比贾母处不同。黛玉便知这方是正经正内室,一条大甬路,直接出大门的。宝玉又想,这里又是什么正宫娘娘所居?前日说送燕窝来,怎么现在竟变成了燕窝铺,只是又没有做得巧妙了。正想着,只见黛玉出来,宝钗忙上来问道:“姐姐往那里去?”黛玉道:“往北方,再过不曾走过。”宝钗道:“这个北,还有个兜儿?”黛玉道:“有的。”宝钗就说:“这个兜子,里面放着的是书,你都看过了,还有什么念头没有?”黛玉道:“都烧了。”宝钗道:“有工夫看这个,还不如\n",
            "--------------------\n",
            "一时黛玉进了荣府,下了车。众嬷嬷引着,便往东转弯,穿过一个东西的穿堂,向南大厅之后,仪门内大院落,上面五间大正房,两边厢房鹿顶耳房钻山,四通八达,轩昂壮丽,比贾母处不同。黛玉便知这方是正经正内室,一条大甬路,直接出大门的。大院落内外,两旁种着苍松翠柏,中间夹着块五色琉璃砖,砌成粉墙,围住着内室。黛玉见了,心中暗想:“这一间房倒象个花园,还要如何?”\n",
            "--------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzwLe5fmi8N_"
      },
      "source": [
        "# 对话例子 (Dialogue Generation)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yaz7N3aFi8OA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73f1f02b-72a0-4305-83b4-8573d249c354"
      },
      "source": [
        "ret = sample(\n",
        "    tokenizer, gpt,\n",
        "    '''A：“今天我想吃火锅”\n",
        "B：“''',\n",
        "    3, 50, top_p=0.9, temperature=0.9)\n",
        "for x in ret:\n",
        "    print(x)\n",
        "    print('-' * 20)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A:“今天我想吃火锅”\n",
            "B:“行,你想吃什么”\n",
            "A:“麻辣烫”\n",
            "B:“我知道了,我要吃火锅”\n",
            "A:“嗯,\n",
            "--------------------\n",
            "A:“今天我想吃火锅”\n",
            "B:“火锅?我就想吃火锅,你想吃火锅我就请客”\n",
            "A:“好,”\n",
            "B:“A你请客”\n",
            "A:“我不\n",
            "--------------------\n",
            "A:“今天我想吃火锅”\n",
            "B:“不好意思,今天我想吃小龙虾”\n",
            "C:“今天我想吃烧烤”\n",
            "D:“不好意思,今天我想吃螃蟹”\n",
            "这种对话经常\n",
            "--------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2C4-JUCmi8OA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2016ca4-65d0-4c46-e203-f7d92b511fb7"
      },
      "source": [
        "ret = sample(\n",
        "    tokenizer, gpt, '''A：“跟我一起去看电影吧”\n",
        "B：“''',\n",
        "    3, 50, top_p=0.9, temperature=0.9)\n",
        "for x in ret:\n",
        "    print(x)\n",
        "    print('-' * 20)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A:“跟我一起去看电影吧”\n",
            "B:“好啊”\n",
            "C:“我可以坐你旁边吗?”\n",
            "D:“可以啊”\n",
            "E:“我看过了,觉得很无聊”\n",
            "\n",
            "--------------------\n",
            "A:“跟我一起去看电影吧”\n",
            "B:“我没时间”\n",
            "C:“那你呢?”\n",
            "A:“我...我......”\n",
            "C:“你也没时间?”\n",
            "A:\n",
            "--------------------\n",
            "A:“跟我一起去看电影吧”\n",
            "B:“那我就得待在家里,我没车”\n",
            "A:“别啊,我带你去看电影吧”\n",
            "B:“那我待在家里又不舒服\n",
            "--------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4lHO3Hhi8OA"
      },
      "source": [
        "# 对联例子 (LM)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bw2C0Vlti8OA"
      },
      "source": [
        "duilian = '''\n",
        "上联天，下联地\n",
        "上联雨，下联风\n",
        "上联大陆，下联长空\n",
        "上联雷隐隐，下联雾蒙蒙\n",
        "上联开心大吉，下联万事亨通\n",
        "'''"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hp-cPBnUi8OB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abcfb73f-ea5a-4794-ecee-1ce290ce578b"
      },
      "source": [
        "ret = sample(\n",
        "    tokenizer, gpt,\n",
        "    duilian + '上联李白作诗，下联',\n",
        "    5, 2, top_p=0.9, temperature=0.9)\n",
        "for x in ret:\n",
        "    print(x)\n",
        "    print('-' * 20)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "上联天,下联地\n",
            "上联雨,下联风\n",
            "上联大陆,下联长空\n",
            "上联雷隐隐,下联雾蒙蒙\n",
            "上联开心大吉,下联万事亨通\n",
            "上联李白作诗,下联杜甫作诗\n",
            "--------------------\n",
            "\n",
            "上联天,下联地\n",
            "上联雨,下联风\n",
            "上联大陆,下联长空\n",
            "上联雷隐隐,下联雾蒙蒙\n",
            "上联开心大吉,下联万事亨通\n",
            "上联李白作诗,下联王安石作\n",
            "--------------------\n",
            "\n",
            "上联天,下联地\n",
            "上联雨,下联风\n",
            "上联大陆,下联长空\n",
            "上联雷隐隐,下联雾蒙蒙\n",
            "上联开心大吉,下联万事亨通\n",
            "上联李白作诗,下联诗仙李白\n",
            "--------------------\n",
            "\n",
            "上联天,下联地\n",
            "上联雨,下联风\n",
            "上联大陆,下联长空\n",
            "上联雷隐隐,下联雾蒙蒙\n",
            "上联开心大吉,下联万事亨通\n",
            "上联李白作诗,下联杜甫作诗\n",
            "--------------------\n",
            "\n",
            "上联天,下联地\n",
            "上联雨,下联风\n",
            "上联大陆,下联长空\n",
            "上联雷隐隐,下联雾蒙蒙\n",
            "上联开心大吉,下联万事亨通\n",
            "上联李白作诗,下联杜甫作诗\n",
            "--------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOkNUOpSi8OB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb913c7c-3e4c-4913-be2d-27a5584aecc0"
      },
      "source": [
        "ret = sample(\n",
        "    tokenizer, gpt,\n",
        "    duilian + '上联追求真爱，下联',\n",
        "    5, 4, top_p=0.9, temperature=0.9)\n",
        "for x in ret:\n",
        "    print(x)\n",
        "    print('-' * 20)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "上联天,下联地\n",
            "上联雨,下联风\n",
            "上联大陆,下联长空\n",
            "上联雷隐隐,下联雾蒙蒙\n",
            "上联开心大吉,下联万事亨通\n",
            "上联追求真爱,下联组建家庭\n",
            "\n",
            "--------------------\n",
            "\n",
            "上联天,下联地\n",
            "上联雨,下联风\n",
            "上联大陆,下联长空\n",
            "上联雷隐隐,下联雾蒙蒙\n",
            "上联开心大吉,下联万事亨通\n",
            "上联追求真爱,下联诚心交友\n",
            "上\n",
            "--------------------\n",
            "\n",
            "上联天,下联地\n",
            "上联雨,下联风\n",
            "上联大陆,下联长空\n",
            "上联雷隐隐,下联雾蒙蒙\n",
            "上联开心大吉,下联万事亨通\n",
            "上联追求真爱,下联追逐金钱\n",
            "上\n",
            "--------------------\n",
            "\n",
            "上联天,下联地\n",
            "上联雨,下联风\n",
            "上联大陆,下联长空\n",
            "上联雷隐隐,下联雾蒙蒙\n",
            "上联开心大吉,下联万事亨通\n",
            "上联追求真爱,下联吉祥如意\n",
            "\n",
            "--------------------\n",
            "\n",
            "上联天,下联地\n",
            "上联雨,下联风\n",
            "上联大陆,下联长空\n",
            "上联雷隐隐,下联雾蒙蒙\n",
            "上联开心大吉,下联万事亨通\n",
            "上联追求真爱,下联事业成功\n",
            "上\n",
            "--------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWINyTrWi8OB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72cdd504-b282-42d8-849b-2e5d2d02de48"
      },
      "source": [
        "ret = sample(\n",
        "    tokenizer, gpt,\n",
        "    duilian + '上联天天向上，下联',\n",
        "    5, 4, top_p=0.9, temperature=0.9)\n",
        "for x in ret:\n",
        "    print(x)\n",
        "    print('-' * 20)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "上联天,下联地\n",
            "上联雨,下联风\n",
            "上联大陆,下联长空\n",
            "上联雷隐隐,下联雾蒙蒙\n",
            "上联开心大吉,下联万事亨通\n",
            "上联天天向上,下联万事如意\n",
            "\n",
            "--------------------\n",
            "\n",
            "上联天,下联地\n",
            "上联雨,下联风\n",
            "上联大陆,下联长空\n",
            "上联雷隐隐,下联雾蒙蒙\n",
            "上联开心大吉,下联万事亨通\n",
            "上联天天向上,下联平平安安\n",
            "\n",
            "--------------------\n",
            "\n",
            "上联天,下联地\n",
            "上联雨,下联风\n",
            "上联大陆,下联长空\n",
            "上联雷隐隐,下联雾蒙蒙\n",
            "上联开心大吉,下联万事亨通\n",
            "上联天天向上,下联真火炎上\n",
            "--------------------\n",
            "\n",
            "上联天,下联地\n",
            "上联雨,下联风\n",
            "上联大陆,下联长空\n",
            "上联雷隐隐,下联雾蒙蒙\n",
            "上联开心大吉,下联万事亨通\n",
            "上联天天向上,下联快乐无边\n",
            "上\n",
            "--------------------\n",
            "\n",
            "上联天,下联地\n",
            "上联雨,下联风\n",
            "上联大陆,下联长空\n",
            "上联雷隐隐,下联雾蒙蒙\n",
            "上联开心大吉,下联万事亨通\n",
            "上联天天向上,下联大团圆\n",
            "上\n",
            "--------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRmr9oNMi8OB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f771dba8-3637-4edf-f566-cf43916701f2"
      },
      "source": [
        "ret = sample(\n",
        "    tokenizer, gpt,\n",
        "    duilian + '上联天地在我心，下联',\n",
        "    5, 4, top_p=0.9, temperature=0.9)\n",
        "for x in ret:\n",
        "    print(x)\n",
        "    print('-' * 20)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "上联天,下联地\n",
            "上联雨,下联风\n",
            "上联大陆,下联长空\n",
            "上联雷隐隐,下联雾蒙蒙\n",
            "上联开心大吉,下联万事亨通\n",
            "上联天地在我心,下联鬼神在我梦\n",
            "--------------------\n",
            "\n",
            "上联天,下联地\n",
            "上联雨,下联风\n",
            "上联大陆,下联长空\n",
            "上联雷隐隐,下联雾蒙蒙\n",
            "上联开心大吉,下联万事亨通\n",
            "上联天地在我心,下联礼义廉耻\n",
            "--------------------\n",
            "\n",
            "上联天,下联地\n",
            "上联雨,下联风\n",
            "上联大陆,下联长空\n",
            "上联雷隐隐,下联雾蒙蒙\n",
            "上联开心大吉,下联万事亨通\n",
            "上联天地在我心,下联春暧花开\n",
            "--------------------\n",
            "\n",
            "上联天,下联地\n",
            "上联雨,下联风\n",
            "上联大陆,下联长空\n",
            "上联雷隐隐,下联雾蒙蒙\n",
            "上联开心大吉,下联万事亨通\n",
            "上联天地在我心,下联鬼神在我胸\n",
            "--------------------\n",
            "\n",
            "上联天,下联地\n",
            "上联雨,下联风\n",
            "上联大陆,下联长空\n",
            "上联雷隐隐,下联雾蒙蒙\n",
            "上联开心大吉,下联万事亨通\n",
            "上联天地在我心,下联情满天下\n",
            "\n",
            "--------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKiF5E8xi8OC"
      },
      "source": [
        "# 名人名言 (LM-Chinese Idiom?)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yj4AhZ3mi8OC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5e6ae60-2fd8-48a2-9cc4-307888af4e9b"
      },
      "source": [
        "ret = sample(\n",
        "    tokenizer, gpt, '''鲁迅曾经说过：“''',\n",
        "    3, 50, top_p=0.9, temperature=0.9)\n",
        "for x in ret:\n",
        "    print(x)\n",
        "    print('-' * 20)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "鲁迅曾经说过:“今日之事,不单是文字狱,实系今世修《古文观止》之人,逐字逐句逐段逐段追查《论语》中‘君子’‘\n",
            "--------------------\n",
            "鲁迅曾经说过:“女人是一种很可怜的动物,男人若是欺负她,她就会跟着男人走。”然而,另一位中国女作家则认为:“男人们之\n",
            "--------------------\n",
            "鲁迅曾经说过:“要把小说当作历史来读,不能抱着猎奇的态度去读。”鲁迅的这个看法在今天看来有些偏激,因为小说是在真实的历史里发生的\n",
            "--------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fopc8r8i8OC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86e927f2-b045-493e-f3df-660c5e31f439"
      },
      "source": [
        "ret = sample(\n",
        "    tokenizer, gpt, '''爱因斯坦曾经说过：“''',\n",
        "    3, 50, top_p=0.9, temperature=0.9)\n",
        "for x in ret:\n",
        "    print(x)\n",
        "    print('-' * 20)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "爱因斯坦曾经说过:“所谓的物理学不过是使我们能够重复已知的事情罢了。”\n",
            "--------------------\n",
            "爱因斯坦曾经说过:“所有的问题都是一个道理:‘为什么’是不可以问的。”但是,他并没有说“不为什么”。他认为\n",
            "--------------------\n",
            "爱因斯坦曾经说过:“只有神才能真正改变物质世界,因为只有神才知道为什么物质世界会是这个样子。”9月9日,在陈云报告的基础上,中央决定\n",
            "--------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFlgJDRXi8OC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96e30608-9e9d-43d0-9266-fadb62c4b465"
      },
      "source": [
        "ret = sample(\n",
        "    tokenizer, gpt, '''牛顿曾经说过：“''',\n",
        "    3, 50, top_p=0.9, temperature=0.9)\n",
        "for x in ret:\n",
        "    print(x)\n",
        "    print('-' * 20)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "牛顿曾经说过:“如果他喜欢的是布施,而不是别的东西,那么布施的结果也就会是宽恕。”对富人来说,钱并非一种选择,它只是一\n",
            "--------------------\n",
            "牛顿曾经说过:“我宁愿做快乐的傻子,也不愿做傻子式的人。”如果你按照这个标准选择职业,我不知道你还能干什么。我想\n",
            "--------------------\n",
            "牛顿曾经说过:“自从世界上出现了蒸汽机和电报,有些人就认为人是无所不能的。”在蒸汽机出现之前,甚至在人们开始认识到电和磁之前,\n",
            "--------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMtke7EPi8OD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "157bc1de-bac6-4cdd-8891-c2700b2dd483"
      },
      "source": [
        "ret = sample(\n",
        "    tokenizer, gpt, '''佛祖曾经说过：“''',\n",
        "    3, 50, top_p=0.9, temperature=0.9)\n",
        "for x in ret:\n",
        "    print(x)\n",
        "    print('-' * 20)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "佛祖曾经说过:“一个人,不管什么时候开始修行,最重要的就是心。”所谓心,就是从悟到的那一刻开始,经过无数次的“观照”,逐\n",
            "--------------------\n",
            "佛祖曾经说过:“一沙一世界,一花一天堂,一叶一如来,一砂一极乐。”他和天,在佛教中,成了对世界的极致描述。如此\n",
            "--------------------\n",
            "佛祖曾经说过:“在众生面前,他总是赤裸裸的。”他对佛祖也同样心知肚明。在一个没有佛祖的时代,当一个人看到一个乞丐,会\n",
            "--------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkinVO7mi8OD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ae18b00-6346-405a-e065-05b056c3937a"
      },
      "source": [
        "ret = sample(\n",
        "    tokenizer, gpt, '''乔布斯曾经说过：“''',\n",
        "    3, 50, top_p=0.9, temperature=0.9)\n",
        "for x in ret:\n",
        "    print(x)\n",
        "    print('-' * 20)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "乔布斯曾经说过:“我们的大脑对输入的东西会进行预处理,让它们变成更加有意思的东西。”在《大教堂与集市》一书中,作者法比奥·\n",
            "--------------------\n",
            "乔布斯曾经说过:“如果你看到一个漂亮的女生,你只需做一件事:就是在她身上花足够的时间。”这句话说的就是这个道理。\n",
            "--------------------\n",
            "乔布斯曾经说过:“软件设计是为人服务的,如果我们要决定一个软件是用来解决什么问题的,最好是问使用者。”一个成功的软件设计应该是以人为本的,而不仅仅\n",
            "--------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_Y5BqDni8OD"
      },
      "source": [
        ""
      ],
      "execution_count": 65,
      "outputs": []
    }
  ]
}