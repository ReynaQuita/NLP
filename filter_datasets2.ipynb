{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "filter_datasets2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ReynaQuita/NLP/blob/main/filter_datasets2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3gJqKO20wOv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f040621-c1b1-499f-cf4b-172822b4c631"
      },
      "source": [
        "! pip install langdetect clean-text[gpl] "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[K     |████████████████████████████████| 981 kB 5.1 MB/s \n",
            "\u001b[?25hCollecting clean-text[gpl]\n",
            "  Downloading clean_text-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from langdetect) (1.15.0)\n",
            "Collecting emoji\n",
            "  Downloading emoji-1.4.2.tar.gz (184 kB)\n",
            "\u001b[K     |████████████████████████████████| 184 kB 17.1 MB/s \n",
            "\u001b[?25hCollecting ftfy<7.0,>=6.0\n",
            "  Downloading ftfy-6.0.3.tar.gz (64 kB)\n",
            "\u001b[K     |████████████████████████████████| 64 kB 1.7 MB/s \n",
            "\u001b[?25hCollecting unidecode<2.0.0,>=1.1.1\n",
            "  Downloading Unidecode-1.2.0-py2.py3-none-any.whl (241 kB)\n",
            "\u001b[K     |████████████████████████████████| 241 kB 18.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy<7.0,>=6.0->clean-text[gpl]) (0.2.5)\n",
            "Building wheels for collected packages: langdetect, ftfy, emoji\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993242 sha256=ccf784a65bff5cb10c18134a577751361c871e117800a5794569f778af332f76\n",
            "  Stored in directory: /root/.cache/pip/wheels/c5/96/8a/f90c59ed25d75e50a8c10a1b1c2d4c402e4dacfa87f3aff36a\n",
            "  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ftfy: filename=ftfy-6.0.3-py3-none-any.whl size=41933 sha256=f6076ec7ec86325308c27d635d55375b943166dcecb27b4fc31238e252549dfc\n",
            "  Stored in directory: /root/.cache/pip/wheels/19/f5/38/273eb3b5e76dfd850619312f693716ac4518b498f5ffb6f56d\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-1.4.2-py3-none-any.whl size=186469 sha256=a53a21477e6278d7eeef3838fb73f7dcd331a375fbebce2b9433fd0f8197dcf5\n",
            "  Stored in directory: /root/.cache/pip/wheels/e4/61/e7/2fc1ac8f306848fc66c6c013ab511f0a39ef4b1825b11363b2\n",
            "Successfully built langdetect ftfy emoji\n",
            "Installing collected packages: ftfy, emoji, unidecode, clean-text, langdetect\n",
            "Successfully installed clean-text-0.4.0 emoji-1.4.2 ftfy-6.0.3 langdetect-1.0.9 unidecode-1.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O42TFhBrsPiG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b980d29-b4ab-4768-d594-e9a039185f40"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qs2c8a7hnxNS"
      },
      "source": [
        "###Load Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmIM9LXxlWc1"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Acif08lPlWiF"
      },
      "source": [
        "\n",
        "# df = pd.read_csv(r'D:\\NewsCommentaryv12WMT17\\training\\en.txt', delimiter = \"\\t\")\n",
        "# df_en = df.rename(columns={\"1929 or 1989?\": 'en'})\n",
        "\n",
        "# df_en\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NkONy7-nyTW"
      },
      "source": [
        "files = [ 'travel' , 'tech' , 'news' , 'music' , 'learning', 'kids' , 'health' , 'ent' , 'business' , 'animation' ]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmpjiNtMnp1I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebcaf673-092f-4731-be69-8c587bfdb1be"
      },
      "source": [
        "b = []\n",
        "for i in files:\n",
        "  a = '/content/gdrive/MyDrive/paper/new/Yi-Chun/Dataset/voicetube/' + i + '/' + 'english_ds_' + i + '.txt'\n",
        "  b.append(a)\n",
        "print(b)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['/content/gdrive/MyDrive/paper/new/Yi-Chun/Dataset/voicetube/travel/english_ds_travel.txt', '/content/gdrive/MyDrive/paper/new/Yi-Chun/Dataset/voicetube/tech/english_ds_tech.txt', '/content/gdrive/MyDrive/paper/new/Yi-Chun/Dataset/voicetube/news/english_ds_news.txt', '/content/gdrive/MyDrive/paper/new/Yi-Chun/Dataset/voicetube/music/english_ds_music.txt', '/content/gdrive/MyDrive/paper/new/Yi-Chun/Dataset/voicetube/learning/english_ds_learning.txt', '/content/gdrive/MyDrive/paper/new/Yi-Chun/Dataset/voicetube/kids/english_ds_kids.txt', '/content/gdrive/MyDrive/paper/new/Yi-Chun/Dataset/voicetube/health/english_ds_health.txt', '/content/gdrive/MyDrive/paper/new/Yi-Chun/Dataset/voicetube/ent/english_ds_ent.txt', '/content/gdrive/MyDrive/paper/new/Yi-Chun/Dataset/voicetube/business/english_ds_business.txt', '/content/gdrive/MyDrive/paper/new/Yi-Chun/Dataset/voicetube/animation/english_ds_animation.txt']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbyKfpjox_pI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a854dcc5-fff2-4165-8dee-bc6c8dfd33cf"
      },
      "source": [
        "d = []\n",
        "for i in files:\n",
        "  c = '/content/gdrive/MyDrive/paper/new/Yi-Chun/Dataset/voicetube/' + i + '/' + 'chinese_ds_' + i + '.txt'\n",
        "  d.append(c)\n",
        "print(d)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['/content/gdrive/MyDrive/paper/new/Yi-Chun/Dataset/voicetube/travel/chinese_ds_travel.txt', '/content/gdrive/MyDrive/paper/new/Yi-Chun/Dataset/voicetube/tech/chinese_ds_tech.txt', '/content/gdrive/MyDrive/paper/new/Yi-Chun/Dataset/voicetube/news/chinese_ds_news.txt', '/content/gdrive/MyDrive/paper/new/Yi-Chun/Dataset/voicetube/music/chinese_ds_music.txt', '/content/gdrive/MyDrive/paper/new/Yi-Chun/Dataset/voicetube/learning/chinese_ds_learning.txt', '/content/gdrive/MyDrive/paper/new/Yi-Chun/Dataset/voicetube/kids/chinese_ds_kids.txt', '/content/gdrive/MyDrive/paper/new/Yi-Chun/Dataset/voicetube/health/chinese_ds_health.txt', '/content/gdrive/MyDrive/paper/new/Yi-Chun/Dataset/voicetube/ent/chinese_ds_ent.txt', '/content/gdrive/MyDrive/paper/new/Yi-Chun/Dataset/voicetube/business/chinese_ds_business.txt', '/content/gdrive/MyDrive/paper/new/Yi-Chun/Dataset/voicetube/animation/chinese_ds_animation.txt']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvU1-SzeiBWf"
      },
      "source": [
        "from cleantext import clean\n",
        "import re"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SgjeOxBYO3x"
      },
      "source": [
        "def clean_chinese_text(context):\n",
        "  context = re.sub(\"http://[a-zA-z./\\d]*\",\"\",context) #Remove links\n",
        "  context = re.sub(\"\\[.{0,12}\\]\",\"\",context) #Remove emoji\n",
        "  tags = re.findall(\"#(.{0,30})#\",context) #Extract and remove tags\n",
        "  context = re.sub(\"#.{0,30}#\",\"\",context)\n",
        "  at = re.findall(\"@([^@]{0,30})\\s\",context) #Extract and remove @somebody\n",
        "  context = re.sub(\"@([^@]{0,30})\\s\",\"\",context)\n",
        "  at+= re.findall(\"@([^@]{0,30})）\",context)\n",
        "  context = re.sub(\"@([^@]{0,30})）\",\"\",context)\n",
        "  context = re.sub(\"[\\s+\\.\\!\\/_,$%^*\\\"\\']+|[+——~@#￥%……&*（）]+\", \"\",context) #Remove punctuation\n",
        "  context = re.sub(\"[【】╮╯▽╰╭★→「」]+\",\"\",context)\n",
        "  context = re.sub(\"！，❤。～《》：（）【】「」？”“；：、\",\"\",context)\n",
        "  context = re.sub(\"\\s\",\"\",context) #Remove space\n",
        "  context = re.sub(\"\\.*\",\"\",context) #Remove ....\n",
        "\n",
        "  return context"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "pikPHxnnkTs-",
        "outputId": "64ff088c-00af-4065-d7b8-3596692224c7"
      },
      "source": [
        "clean(\"Oh my God\",fix_unicode=False, to_ascii=False, no_urls=True, replace_with_url=\"\", no_emails=True, replace_with_email=\"\", no_punct=False, replace_with_punct=\"\", lower=False, lang =\"en\") "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Oh my God'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "F2uLIN8TYefT",
        "outputId": "77e0eac1-2e64-4dd6-afd6-311eed74afd3"
      },
      "source": [
        "clean_chinese_text(\"我們都非常興奮，(那位戴著兔耳朵的仁兄也是##)。\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'我們都非常興奮，(那位戴著兔耳朵的仁兄也是)。'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwQ-mPhslerV"
      },
      "source": [
        "en_list = []\n",
        "\n",
        "for k in b:\n",
        "  with open(k,'r') as fh:\n",
        "    for oneline in fh:\n",
        "      oneline = oneline.strip()\n",
        "      oneline = clean(oneline, fix_unicode=True, to_ascii=True, no_urls=True, replace_with_url=\"\",  lower=False, no_emails=True, replace_with_email=\"\", no_punct=False, replace_with_punct=\"\", lang =\"en\") \n",
        "      en_list.append(oneline)\n",
        "#    for i in en_list:\n",
        "#        print(i)\n",
        "\n",
        "x_dic={}\n",
        "x_dic['en'] = en_list\n",
        "df_en = pd.DataFrame( data = x_dic )\n",
        "\n",
        "df_en"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgBrCicuv40b"
      },
      "source": [
        "len(df_en)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vY03I7gkllUe"
      },
      "source": [
        "\n",
        "# df2 = pd.read_csv(r'D:\\NewsCommentaryv12WMT17\\training\\zh.txt', delimiter = \"\\t\")\n",
        "# df_zh = df2.rename(columns={\"1929年还是1989年?\": 'zh'})\n",
        "\n",
        "# df_zh\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cwoz9hJmpZX7"
      },
      "source": [
        "zh_list = []\n",
        "\n",
        "for k in d:  \n",
        "  with open(k,'r') as fh:\n",
        "#    zh_list = []\n",
        "    for oneline in fh:\n",
        "      oneline = clean_chinese_text(oneline.strip())\n",
        "      zh_list.append(oneline)\n",
        "#    for i in zh_list:\n",
        "#        print(i)\n",
        "\n",
        "y_dic={}\n",
        "y_dic['zh'] = zh_list\n",
        "df_zh = pd.DataFrame( data = y_dic )\n",
        "\n",
        "df_zh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBrc3mod0fHH"
      },
      "source": [
        "len(df_zh)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VC1mBpo5ls0J"
      },
      "source": [
        "df_en_zh = pd.concat([df_en, df_zh], axis=1)\n",
        "\n",
        "df_en_zh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOBL4TInl2-v"
      },
      "source": [
        "###Remove Nan Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L368j6Ttlyl-"
      },
      "source": [
        "df_en_zh.dropna(inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvGvCiLZlyow"
      },
      "source": [
        "df_en_zh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CyXof1C2mAxi"
      },
      "source": [
        "###Filter Length"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fJBTjfi39Ir"
      },
      "source": [
        "# import  jieba"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ZSMwXut3-oT"
      },
      "source": [
        "english = []\n",
        "chinese = []\n",
        "\n",
        "for i in range(0,len(df_en_zh)):\n",
        "  if len(df_en_zh['en'][i].split()) > 6:\n",
        "    if len(df_en_zh['zh'][i]) > 6:\n",
        "      english.append(df_en_zh['en'][i])\n",
        "      chinese.append(df_en_zh['zh'][i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoOgrb7smPsk"
      },
      "source": [
        "len(english), len(chinese)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OM-1GpjmToD"
      },
      "source": [
        "df_eng = pd.DataFrame(english, columns =['en'])\n",
        "df_chi = pd.DataFrame(chinese, columns =['zh'])\n",
        "\n",
        "df_en_zh2 = pd.concat([df_eng, df_chi], axis=1)\n",
        "df_en_zh2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLYyuMpGmoF1"
      },
      "source": [
        "###Filter Language"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-i8KA99DmcnU"
      },
      "source": [
        "from langdetect import detect"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Slz3NZl0mzTD"
      },
      "source": [
        "english = []\n",
        "chinese = []\n",
        "no_en = []\n",
        "no_zh = []\n",
        "\n",
        "for i in range(0,len(df_en_zh2)):\n",
        "  try:\n",
        "    if detect(df_en_zh2['en'][i]) == 'en':\n",
        "      if detect(df_en_zh2['zh'][i]) == 'zh-tw':\n",
        "        english.append(df_en_zh2['en'][i])\n",
        "        chinese.append(df_en_zh2['zh'][i])\n",
        "      else:\n",
        "        no_en.append(df_en_zh2['en'][i])\n",
        "        no_zh.append(df_en_zh2['zh'][i])\n",
        "  except:\n",
        "    print(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPqYvlikm1W2"
      },
      "source": [
        "len(english), len(chinese)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFE6t6chm29h"
      },
      "source": [
        "df_eng = pd.DataFrame(english, columns =['en'])\n",
        "df_chi = pd.DataFrame(chinese, columns =['zh'])\n",
        "\n",
        "df_en_zh3 = pd.concat([df_eng, df_chi], axis=1)\n",
        "df_en_zh3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpX7hRGa4lkf"
      },
      "source": [
        "###Remove Duplicate Sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJQonVLq4lFC"
      },
      "source": [
        "df_en_zh3 = df_en_zh3.drop_duplicates(ignore_index=True)\n",
        "df_en_zh3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wZQEEap4xbG"
      },
      "source": [
        "len(df_en_zh3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9v1gJW744Ao"
      },
      "source": [
        "###chinese length between -10% until 55% of the english length"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUSz4lD_48-C"
      },
      "source": [
        "english = []\n",
        "chinese = []\n",
        "\n",
        "#source: english, target: chinese\n",
        "for i in range(0,len(df_en_zh3)):\n",
        "  en_length = len(df_en_zh3['en'][i].split())\n",
        "  zh_length = len(df_en_zh3['zh'][i])\n",
        "  en_length_1 = en_length - en_length*0.1\n",
        "  en_length_2 = en_length + en_length*0.55     \n",
        "\n",
        "\n",
        "  if (en_length_1 < zh_length < en_length_2):\n",
        "      english.append(df_en_zh3['en'][i])\n",
        "      chinese.append(df_en_zh3['zh'][i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XASR2Sh5PN0"
      },
      "source": [
        "len(english), len(chinese)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sBQnWPt5R3T"
      },
      "source": [
        "df_eng = pd.DataFrame(english, columns =['en'])\n",
        "df_chi = pd.DataFrame(chinese, columns =['zh'])\n",
        "\n",
        "df_en_zh4 = pd.concat([df_eng, df_chi], axis=1)\n",
        "df_en_zh4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jgl2rv4VLjjd"
      },
      "source": [
        "df_eng"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbxwHf7WLk_o"
      },
      "source": [
        "df_chi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWaJM82Po7ny"
      },
      "source": [
        "###Download Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xz295tdyMMVJ"
      },
      "source": [
        "df_eng.to_csv(r'en_all_new.csv' , index = False)\n",
        "df_chi.to_csv(r'zh_all_new.csv' , index = False)\n",
        "df_en_zh4.to_csv(r'en_zh_all_new.csv' , index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLH_x0cUfzQn"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download(\"en_all_new.csv\")\n",
        "files.download(\"zh_all_new.csv\")\n",
        "files.download(\"en_zh_all_new.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQQSn_KknGRm"
      },
      "source": [
        "###Creat Dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHwB3c91m-sx"
      },
      "source": [
        "# Convert the DataFrame to Series\n",
        "'''\n",
        "dictionaryObject = df_en_zh4.to_dict('record')\n",
        "dictionaryObject\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqCLIvTanB4r"
      },
      "source": [
        "'''\n",
        "z_dic={}\n",
        "z_dic['translation'] = dictionaryObject\n",
        "dff = pd.DataFrame( data = z_dic )\n",
        "td = Dataset.from_dict( dff )\n",
        "\n",
        "td\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}